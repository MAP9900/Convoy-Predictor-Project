<!--  index1_1 used to showcase the original models which focused on prediction rather than classification-->
<!-- Updated 9/26 with Re-Ran results from Regression_Test_2-->
 
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Convoy Machine Learning (Old Models)</title>
    <link rel="stylesheet" href="styles.css"> <!-- Link to external CSS file -->
</head>
<body>

    <!-- Header Section -->
    <header>
        <h1>Convoy Machine Learning</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li> <!-- Link back to homepage -->
                <li><a href="section1.html">Convoy Machine Learning</a></li> <!-- Link to Section 1 Page -->
                <li><a href="section6.html">Results</a></li> <!-- Link to Section 6 Page -->
                <li><a href="section2.html">Convoy Data Visualization</a></li> <!-- Link to Section 2 Page -->
                <li><a href="section3.html">Convoy History</a></li> <!-- Link to Section 3 Page -->
                <li><a href="section4.html">Original Project</a></li> <!-- Link to Section 4 Page -->
                <li><a href="section5.html">Additional Info</a></li> <!-- Link to Section 5 Page -->
            </ul>
        </nav>
    </header>
    <!-- Main Section --- Original Models -->
     <main>
        <h2 style="text-align: center;">Original Regression Approach:</h2>
        <p class="centered-paragraph">
            The original goal of the project was to predict convoys' exact sink percentages through machine learning regression techniques. 
            Linear Regression, Random Forest Regressor, and Gradient Boosting Regressor models were deemed the most applicable models in this first
            approach. A link to the initial notebook with these preliminary results can be found
            <a href="https://github.com/MAP9900/Convoy-Predictor-Project/blob/main/notebooks/exploration/Regression_Test_2.ipynb" target="_blank">here</a>.
            Below are the results for the three models first tested. Although no optimization was done to improve the models, the extremely low test score results 
            indicate a regression approach is not feasible. 

        </p>
    
        <div class="table-container">
            <!-- Linear Regression Table -->
            <table>
                <tr><th colspan="2">Linear Regression</th></tr>
                <tr><td>Train Score (R<sup>2</sup>)</td><td>0.1197</td></tr>
                <tr><td>Test Score (R<sup>2</sup>)</td><td>0.0947</td></tr>
                <!-- <tr><td>Coefficients</td><td>[1.1196, 0.2562, 0.6230, -1.5004, 0.1397, -0.5358, 0.0087, 0.1338, 0.0369, 0.7472, 0.0465]</td></tr> -->
                <tr><td>Intercept</td><td>1.1144</td></tr>
                <tr><td>K-Fold Train Score (Mean R<sup>2</sup>)</td><td>0.1189</td></tr>
                <tr><td>K-Fold Test Score (Mean R<sup>2</sup>)</td><td>0.0480</td></tr>
            </table>
    
            <!-- Random Forest Table -->
            <table>
                <tr><th colspan="2">Random Forest Regressor</th></tr>
                <tr><td>Train Score (R<sup>2</sup>)</td><td>0.8609</td></tr>
                <tr><td>Test Score (R<sup>2</sup>)</td><td>0.0282</td></tr>
                <tr><td>Mean Squared Error</td><td>13.9292</td></tr>
                <tr><td>K-Fold Train Score (Mean R<sup>2</sup>)</td><td>0.8615</td></tr>
                <tr><td>K-Fold Test Score (Mean R<sup>2</sup>)</td><td>-0.1785</td></tr>
            </table>
    
            <!-- Gradient Boosting Table -->
            <table>
                <tr><th colspan="2">Gradient Boosting Regressor</th></tr>
                <tr><td>Train Score (R<sup>2</sup>)</td><td>0.8108</td></tr>
                <tr><td>Test Score (R<sup>2</sup>)</td><td>0.0707</td></tr>
                <tr><td>Mean Squared Error</td><td>13.3208</td></tr>
                <tr><td>K-Fold Train Score (Mean R<sup>2</sup>)</td><td>0.7650</td></tr>
                <tr><td>K-Fold Test Score (Mean R<sup>2</sup>)</td><td>-0.2243</td></tr>
            </table>
        </div>
     <!-- Images container -->
    <div class="image-container">
        <img src="images/LinReg_TP.png" alt="Linear Regression Visualization">
        <img src="images/RanFor_TP.png" alt="Random Forest Visualization">
        <img src="images/GB_TP.png" alt="Gradient Boosting Visualization">
    </div>
    <p class="centered-paragraph">
        All three regression models underperformed on the test data, highlighting their weak predictive power. 
        Linear Regression barely improved over a naive baseline (train R² 0.1197 vs. test R² 0.0947), while Random Forest 
        and Gradient Boosting appeared to overfit the data (train R² ≈0.86 and mean accuracy ≈0.81 vs. test R² 0.0282 and mean accuracy 0.0707).
        Combined with outliers where convoys suffered heavy losses and the many unmodeled wartime factors (weather, night/day, U-boat tactics, etc.),
        predicting a precise sink percentage is unrealistic. Going forward, the target variable will be switched to a binary value of 0 
        (no ships sunk) or 1 (at least one ship sunk). This new focus will aim at identifying high-risk convoys rather than estimating exact sink percentages. 
    </p>
    </main>

    
