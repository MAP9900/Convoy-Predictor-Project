<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Convoy Machine Learning</title>
    <link rel="stylesheet" href="styles.css"> <!-- Link to external CSS file -->
</head>
<body>
    
    <!-- Header Section -->
    <header>
        <h1>Convoy Machine Learning</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li> <!-- Link back to homepage -->
                <li><a href="section2.html">Convoy Data Visualization</a></li> <!-- Link to Section 2 Page -->
                <li><a href="section3.html">Convoy History</a></li> <!-- Link to Section 3 Page -->
                <li><a href="section4.html">Original Project</a></li> <!-- Link to Section 4 Page -->
                <li><a href="section5.html">Additional Info</a></li> <!-- Link to Section 5 Page -->
            </ul>
        </nav>
    </header>

    <main>
        
<!-- Original Classification Results -->
        <h2 style="text-align: center;"> </strong>Exploring Classification Algorithms</h2>
        <p class="centered-paragraph">
        The original scope of this project aimed to predict a convoy's precise sink percentage. The results for these 
        test can be found <a href="section1_1.html">here.</a>
        
        This method quickly proved to be far too difficult largely due to limited data and widely varying sink percentages.
        Instead, sink percentages were converted to binary values of 0 (no ships sunk) or 1 (at least one ship sunk). 
        This new method aims to alleviate the complexity of predicting an exact sink percentage while also providing
        a more realistic approach of classifying convoys as at risk vs. not as risk. 
        
    
        </p>
        

    
    </main>
    

    <!-- Footer Section -->
    <footer>
        <p>&copy; 2025 Matthew Plambeck</p>
    </footer>

</body>
</html>


<!-- Old HTML Code, used to reference how tables were made

</p>
    <div class="table-container">
        Logistic Regression Results 
        <table>
            <tr><th colspan="2">Logistic Regression</th></tr>
            <tr><td>Train Score (Mean Accuracy)</td><td>0.811965811965812</td></tr>
            <tr><td>Test Score (Mean Accuracy)</td><td>0.8068181818181818</td></tr>
            <tr><td>Mean Squared Error</td><td>0.19318181818181818</td></tr>
            <tr><td>K-Fold Train Score</td><td>0.8071378962697434</td></tr>
            <tr><td>K-Fold Test Score</td><td>0.8075365726227796</td></tr>
        </table>

        Random Forest Results
        <table>
            <tr><th colspan="2">Random Forest Classifier</th></tr>
            <tr><td>Train Score (Mean Accuracy)</td><td>1.0</td></tr>
            <tr><td>Test Score (Mean Accuracy)</td><td>0.8579545454545454</td></tr>
            <tr><td>Mean Squared Error</td><td>0.14204545454545456</td></tr>
            <tr><td>K-Fold Train Score</td><td>1.0</td></tr>
            <tr><td>K-Fold Test Score</td><td>0.8370950888192269</td></tr>
        </table>

        Gradient Boosting Results 
        <table>
            <tr><th colspan="2">Gradient Boosting</th></tr>
            <tr><td>Train Score (Mean Accuracy)</td><td>0.9487179487179487</td></tr>
            <tr><td>Test Score (Mean Accuracy)</td><td>0.8693181818181818</td></tr>
            <tr><td>Mean Squared Error</td><td>0.13068181818181818</td></tr>
            <tr><td>K-Fold Train Score</td><td>0.9383702731680776</td></tr>
            <tr><td>K-Fold Test Score</td><td>0.8336729362591433</td></tr>
        </table>
    </div>

    <div class="table-container">
        Random Forest Classifier Report
        <table border="1">
            <tr><th colspan="5">Random Forest Classification Report</th></tr>
            <tr><th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th></tr>
            <tr><td>0 (No Risk)</td><td>0.87</td><td>0.97</td><td>0.92</td><td>141</td></tr>
            <tr><td>1 (At Risk)</td><td>0.78</td><td>0.40</td><td>0.53</td><td>35</td></tr>
            <tr><td>Macro Avg</td><td>0.82</td><td>0.69</td><td>0.72</td><td>176</td></tr>
            <tr><td>Weighted Avg</td><td>0.85</td><td>0.86</td><td>0.84</td><td>176</td></tr>
            <tr><td>Accuracy</td><td colspan="4">0.86 (176 total)</td></tr>
        </table>
        
        Logistic Regression Classification Report 
        <table border="1">
            <tr><th colspan="5">Logistic Regression Classification Report</th></tr>
            <tr><th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th></tr>
            <tr><td>0 (No Risk)</td><td>0.81</td><td>0.99</td><td>0.89</td><td>141</td></tr>
            <tr><td>1 (At Risk)</td><td>0.60</td><td>0.09</td><td>0.15</td><td>35</td></tr>
            <tr><td>Macro Avg</td><td>0.71</td><td>0.54</td><td>0.52</td><td>176</td></tr>
            <tr><td>Weighted Avg</td><td>0.77</td><td>0.81</td><td>0.74</td><td>176</td></tr>
            <tr><td>Accuracy</td><td colspan="4">0.81 (176 total)</td></tr>
        </table>
    
        Gradient Boosting Classification Report
        <table border="1">
            <tr><th colspan="5">Gradient Boosting Classifier Classification Report</th></tr>
            <tr><th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th></tr>
            <tr><td>0 (No Risk)</td><td>0.88</td><td>0.97</td><td>0.92</td><td>141</td></tr>
            <tr><td>1 (At Risk)</td><td>0.80</td><td>0.46</td><td>0.58</td><td>35</td></tr>
            <tr><td>Macro Avg</td><td>0.84</td><td>0.71</td><td>0.75</td><td>176</td></tr>
            <tr><td>Weighted Avg</td><td>0.86</td><td>0.87</td><td>0.85</td><td>176</td></tr>
            <tr><td>Accuracy</td><td colspan="4">0.87 (176 total)</td></tr>
        </table>
    </div>
    
    <p class="centered-paragraph">
        The results indicate classification to be the better approach. Predicting an exact sink percentage is simply too unrealistic and 
        arguably not very valuable in a real world setting. The best classifier, currently, the the gradient boosting classifier with a 
        recall score of 0.46 for at risk convoys and a precision score of 0.88 for no risk convoys. These two metrics, I deem, are the most
        import in protecting convoys. My aim is the maximize the number of true positives for convoys at risk and minimize the number false positives
        for convoys at no risk. In the real world context of convoys, lives, ships, and cargo at are stake and thus, correctly predicting convoys at 
        risk is the most important. The instances of false positives for convoys at risk (precision for at risk), although not ideal, lends to
        a level of caution in protecting convoys. If a convoy may be at risk, than, I believe, it is better to classify it as an at risk convoy
        than not as a precautionary measure. Although, in the real world, this approach may be limited/unrealistic if a finite number of resources
        (escort ships, air-cover, etc) can be allocated to convoys and thus only convoys truly at risk can afford to have more protection resources. 
        Regardless, precision and recall for convoys at risk and not a risk will be optimized in further refinements of the classifiers. The link 
        to the code for all of the results above (regressors and classifications) can be found 
        <a href="https://github.com/MAP9900/Modeling-The-Convoy-System/blob/main/Code/Machine%20Learning/Convoy_Model_2.ipynb" target="_blank">here</a>. <br>
        
    </p> -->