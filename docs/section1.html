<!--TODO Test other promising algorithms -->



<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Convoy Machine Learning</title>
    <link rel="stylesheet" href="styles.css"> <!-- Link to external CSS file -->
</head>
<body>
    
    <!-- Header Section -->
    <header>
        <h1>Convoy Machine Learning</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li> <!-- Link back to homepage -->
                <li><a href="section6.html">Results</a></li> <!-- Link to Section 6 Page -->
                <li><a href="section2.html">Convoy Data Visualization</a></li> <!-- Link to Section 2 Page -->
                <li><a href="section3.html">Convoy History</a></li> <!-- Link to Section 3 Page -->
                <li><a href="section4.html">Original Project</a></li> <!-- Link to Section 4 Page -->
                <li><a href="section5.html">Additional Info</a></li> <!-- Link to Section 5 Page -->
            </ul>
        </nav>
    </header>

    <main>
        
<!-- Original Classification Results -->
        <h2 style="text-align: center;"> </strong>Exploring Classification Algorithms</h2>
        <p class="centered-paragraph">
        

        Early experiments utilized a regression approach to predict exact sink percentages. The results for these initial attempts 
        can be found <a href="section1_1.html">here.</a> The limited data, wide variability, and unmodeled factors 


        This method quickly proved to be far too difficult largely due to limited data and widely varying sink percentages.
        Instead, sink percentages were converted to binary values of 0 (no ships sunk) or 1 (at least one ship sunk). 
        This new method aims to alleviate the complexity of predicting an exact sink percentage while also providing
        a more realistic approach of identifying high-risk convoys. Various algorithms were tested to 
        determine the one best suited for the challenge.
        
    
        </p>
        
        <div class="table-container">
            <table>
                <caption>Classification Algorithm Comparison:</caption>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Acc</th>
                        <th>ROC_AUC</th>
                        <th>MCC</th>
                        <th>Bal_Acc</th>
                        <th>Recall1</th>
                        <th>F1_1</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>LogisticRegression</td><td>0.79</td><td>0.786</td><td>0.193</td><td>0.554</td><td>0.14</td><td>0.22</td></tr>
                    <tr><td>SGDClassifier</td><td>0.79</td><td>0.728</td><td>0.148</td><td>0.537</td><td>0.10</td><td>0.17</td></tr>
                    <tr><td>LinearSVC</td><td>0.79</td><td>0.535</td><td>0.000</td><td>0.500</td><td>0.00</td><td>0.00</td></tr>
                    <tr><td>SVC</td><td>0.80</td><td>0.768</td><td>0.215</td><td>0.545</td><td>0.10</td><td>0.18</td></tr>
                    <tr><td>NuSVC</td><td>0.77</td><td>0.667</td><td>0.241</td><td>0.606</td><td>0.32</td><td>0.37</td></tr>
                    <tr><td>KNeighborsClassifier</td><td>0.80</td><td>0.740</td><td>0.265</td><td>0.588</td><td>0.22</td><td>0.32</td></tr>
                    <tr><td>RadiusNeighborsClassifier</td><td>0.78</td><td>0.567</td><td>-0.034</td><td>0.497</td><td>0.00</td><td>0.00</td></tr>
                    <tr><td>DecisionTreeClassifier</td><td>0.74</td><td>0.621</td><td>0.235</td><td>0.621</td><td>0.42</td><td>0.40</td></tr>
                    <tr><td>RandomForestClassifier</td><td>0.84</td><td>0.815</td><td>0.461</td><td>0.674</td><td>0.38</td><td>0.51</td></tr>
                    <tr><td>ExtraTreesClassifier</td><td>0.84</td><td>0.791</td><td>0.469</td><td>0.688</td><td>0.42</td><td>0.53</td></tr>
                    <tr><td>BaggingClassifier</td><td>0.83</td><td>0.766</td><td>0.400</td><td>0.656</td><td>0.36</td><td>0.47</td></tr>
                    <tr class="highlight-row"><td>GradientBoostingClassifier</td><td>0.84</td><td>0.835</td><td>0.473</td><td>0.696</td><td>0.44</td><td>0.54</td></tr>
                    <tr><td>AdaBoostClassifier</td><td>0.82</td><td>0.790</td><td>0.368</td><td>0.631</td><td>0.30</td><td>0.42</td></tr>
                    <tr><td>GaussianNB</td><td>0.77</td><td>0.670</td><td>0.096</td><td>0.530</td><td>0.12</td><td>0.18</td></tr>
                    <tr><td>BernoulliNB</td><td>0.79</td><td>0.699</td><td>0.000</td><td>0.500</td><td>0.00</td><td>0.00</td></tr>
                    <tr><td>ComplementNB</td><td>0.49</td><td>0.555</td><td>0.061</td><td>0.537</td><td>0.62</td><td>0.34</td></tr>
                    <tr><td>LinearDiscriminantAnalysis</td><td>0.79</td><td>0.787</td><td>0.205</td><td>0.561</td><td>0.16</td><td>0.25</td></tr>
                    <tr><td>QuadraticDiscriminantAnalysis</td><td>0.78</td><td>0.790</td><td>0.425</td><td>0.735</td><td>0.66</td><td>0.56</td></tr>
                    <tr><td>MLPClassifier</td><td>0.67</td><td>0.542</td><td>-0.064</td><td>0.471</td><td>0.12</td><td>0.13</td></tr>
                </tbody>
            </table>
        </div>
        <p class="centered-paragraph">
        The Gradient Boosting Classifier performs the best on this data and will be the foundation for all future tests. <br>
         Notably, the ComplementNB and QuadraticDiscriminantAnalysis algorithms performed comparable, even resulting in higher recall scores.  <br>
        Other Gradient Boosting algorithms from the XGBoost library will be tested next. These results are below.


        </p>

        <div class="table-container">
            <table>
                <caption>Gradient Boosting Family Comparison:</caption>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Acc</th>
                        <th>ROC_AUC</th>
                        <th>MCC</th>
                        <th>Bal_Acc</th>
                        <th>Recall1</th>
                        <th>F1_1</th>
                    </tr>
                </thead>
                <tbody>
                    <tr class="highlight-row"><td>GradientBoostingClassifier</td><td>0.84</td><td>0.835</td><td>0.473</td><td>0.696</td><td>0.44</td><td>0.54</td></tr>
                    <tr><td>XGBClassifier</td><td>0.83</td><td>0.773</td><td>0.408</td><td>0.651</td><td>0.34</td><td>0.46</td></tr>
                    <tr><td>LGBMClassifier</td><td>0.83</td><td>0.792</td><td>0.443</td><td>0.683</td><td>0.42</td><td>0.52</td></tr>
                    <tr><td>CatBoostClassifier</td><td>0.84</td><td>0.832</td><td>0.457</td><td>0.659</td><td>0.34</td><td>0.48</td></tr>
                </tbody>
            </table>
        </div>

        <p class="centered-paragraph">
            The regular Scikit-Learn Gradient Boosting edges out the other boosted tree variants by pairing the top ROC-AUC 
            and F1 scores with the strongest recall for at-risk convoys. Further optimization will now be done with focus put on recall and false negatives. 
            The emphasis on recall, which measures true positives over true positives plus false negatives, is done because detecting convoys at risk is more 
            important than detecting not at risk convoys. False positive cases (where the model says a convoy is not a risk despite it being at risk) are particularly
            dangerous for this problem especially with human life and crucial wartime supplies on the line. False positives, though not ideal, carry much less risk associated
            with them. If a convoy is labeled as at risk but in actuality was not, no harms comes a result. Now limitations here do exist such as allocating defensive resources 
            otherwise one would label every convoy at risk. However, some false positives are acceptable as a form of caution.  

        </p>

        <!-- Gradient Boosting Classifier Detailed Results -->



    <h2 style="text-align: center;">Optimizing the Gradient Boosting Model and Comparing Thresholds</h2>

     <p class="centered-paragraph">
        To optimize the gradient boosting classifier, Grid Search Cross Validation will be used to test a predefined set of hyperparameters. The hyperparameters 
        optimized are learning_rate, n_estimators, max_depth, min_samples_leaf, min_samples_split, subsample, and max_features. To learn more about these hyperparameters
        see Scikit-Learn's docs <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" target="_blank">here</a>. 
        After Gris Search CV, a threshold comparison is done to examine the affect on recall, precision, and accuracy. Threshold, which defaults to 0.5, is the value used to 
        convert the model's probability output into a discrete class (0 or 1). With the default value of 0.5, any output below 0.5 will be classified as 0 and above 0.5, will be a 1.
        By manipulating the threshold, more weight can be onto recall and limiting the number of false negatives at the expense of decreasing precision and increasing the number of
        false positives. The results for the optimized classifier and threshold comparison are below. 

        </p>
        <br>
        <section class="table-section">
            <!-- <h3>Threshold Comparison</h3> -->
            <div class="table-block table-pair">
                <table>
                    <caption>Optimized GB Classifier Threshold Comparison (0.00 – 0.50)</caption>
                    <thead>
                        <tr>
                            <th>Threshold</th>
                            <th>Recall</th>
                            <th>Precision</th>
                            <th>False Negatives</th>
                            <th>Accuracy</th>
                            <th>F1-Score</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>0.00</td><td>1.00</td><td>0.212766</td><td>0</td><td>0.212766</td><td>0.175439</td></tr>
                        <tr><td>0.05</td><td>0.86</td><td>0.361345</td><td>7</td><td>0.646809</td><td>0.616564</td></tr>
                        <tr><td>0.10</td><td>0.80</td><td>0.449438</td><td>10</td><td>0.748936</td><td>0.698646</td></tr>
                        <tr><td>0.15</td><td>0.72</td><td>0.480000</td><td>14</td><td>0.774468</td><td>0.711188</td></tr>
                        <tr><td>0.20</td><td>0.68</td><td>0.523077</td><td>16</td><td>0.800000</td><td>0.729455</td></tr>
                        <tr><td>0.25</td><td>0.64</td><td>0.551724</td><td>18</td><td>0.812766</td><td>0.735523</td></tr>
                        <tr><td>0.30</td><td>0.64</td><td>0.592593</td><td>18</td><td>0.829787</td><td>0.753047</td></tr>
                        <tr><td>0.35</td><td>0.60</td><td>0.600000</td><td>20</td><td>0.829787</td><td>0.745946</td></tr>
                        <tr><td>0.40</td><td>0.54</td><td>0.600000</td><td>23</td><td>0.825532</td><td>0.729544</td></tr>
                        <tr><td>0.45</td><td>0.46</td><td>0.575000</td><td>27</td><td>0.812766</td><td>0.697661</td></tr>
                        <tr><td>0.50</td><td>0.42</td><td>0.567568</td><td>29</td><td>0.808511</td><td>0.682633</td></tr>
                    </tbody>
                </table>
                <table>
                    <caption>Optimized GB Classifier Threshold Comparison (0.55 – 1.00)</caption>
                    <thead>
                        <tr>
                            <th>Threshold</th>
                            <th>Recall</th>
                            <th>Precision</th>
                            <th>False Negatives</th>
                            <th>Accuracy</th>
                            <th>F1-Score</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>0.55</td><td>0.40</td><td>0.555556</td><td>30</td><td>0.804255</td><td>0.672662</td></tr>
                        <tr><td>0.60</td><td>0.36</td><td>0.620690</td><td>32</td><td>0.817021</td><td>0.672861</td></tr>
                        <tr><td>0.65</td><td>0.34</td><td>0.653846</td><td>33</td><td>0.821277</td><td>0.670385</td></tr>
                        <tr><td>0.70</td><td>0.32</td><td>0.640000</td><td>34</td><td>0.817021</td><td>0.658903</td></tr>
                        <tr><td>0.75</td><td>0.32</td><td>0.695652</td><td>34</td><td>0.825532</td><td>0.667541</td></tr>
                        <tr><td>0.80</td><td>0.30</td><td>0.714286</td><td>35</td><td>0.825532</td><td>0.659889</td></tr>
                        <tr><td>0.85</td><td>0.24</td><td>0.705882</td><td>38</td><td>0.817021</td><td>0.625755</td></tr>
                        <tr><td>0.90</td><td>0.14</td><td>0.700000</td><td>43</td><td>0.804255</td><td>0.560569</td></tr>
                        <tr><td>0.95</td><td>0.12</td><td>0.857143</td><td>44</td><td>0.808511</td><td>0.550784</td></tr>
                        <tr><td>1.00</td><td>0.00</td><td>0.000000</td><td>50</td><td>0.787234</td><td>0.440476</td></tr>
                    </tbody>
                </table>
            </div>
        </section>

        <figure>
                <h4>Visualization of Different Thresholds</h4>
                <img src="images/Optimized_GB_Threshold_Results.png" alt="Visualization of Different Thresholds" width="750" height="500">
                <!-- <figcaption>____</figcaption> -->
            </figure>

     <p class="centered-paragraph">
        The threshold comparison results indicate a threshold interval of [0.25, 0.35] to be the best performing. At a threshold of 0.30, f1-score peaks at 
        0.75 and so does accuracy at 0.83 given the best balance between recall and precision. However, the number of false negatives remains relatively high
        at 18 convoys classified as not a risk despite having ships sunk. So a recall focused best interval for threshold is instead at [0.05, 0.15]. At this interval.
        false negatives are 7, 10, & 14 respectively. These results are more in line with goal of producing a model with a high recall score. Accuracy and f1-score 
        remain high at a threshold of 0.15 but quickly begin at thresholds of 0.10 and 0.05. Thus determining a single, optimal threshold is difficult with each value 
        having trade offs between the different metrics. A good balance, however, between these two threshold intervals is 0.20. Recall, accuracy and f1-score 
        remain high at 0.68, 0.80, 0.73 respectively with only 16 false negatives occurring. 
     </p>
    
    <h2 style="text-align: center;">Exploring Other Promising Algorithms</h2>
    <p class="centered-paragraph">
        From the results above and previous tests, other algorithms displayed strong abilities to have strong recall scores along with accuracy and f1-scores. 
        Those algorithms were the ComplementNB and QuadraticDiscriminantAnalysis along with other gradient boosting based algorithms from the XGBoost library.
        These algorithms will now be tested and optimized to see if they can outperform the gradient boosting classifier. 
    </p> <br>
    <p class="centered-paragraph">Results Coming Soon!</p>


    </main>
    

    <!-- Footer Section -->
    <footer>
        <p>&copy; 2025 Matthew Plambeck</p>
    </footer>

</body>
</html>


<!-- Old HTML Code, used to reference how tables were made

</p>
    <div class="table-container">
        Logistic Regression Results 
        <table>
            <tr><th colspan="2">Logistic Regression</th></tr>
            <tr><td>Train Score (Mean Accuracy)</td><td>0.811965811965812</td></tr>
            <tr><td>Test Score (Mean Accuracy)</td><td>0.8068181818181818</td></tr>
            <tr><td>Mean Squared Error</td><td>0.19318181818181818</td></tr>
            <tr><td>K-Fold Train Score</td><td>0.8071378962697434</td></tr>
            <tr><td>K-Fold Test Score</td><td>0.8075365726227796</td></tr>
        </table>

        Random Forest Results
        <table>
            <tr><th colspan="2">Random Forest Classifier</th></tr>
            <tr><td>Train Score (Mean Accuracy)</td><td>1.0</td></tr>
            <tr><td>Test Score (Mean Accuracy)</td><td>0.8579545454545454</td></tr>
            <tr><td>Mean Squared Error</td><td>0.14204545454545456</td></tr>
            <tr><td>K-Fold Train Score</td><td>1.0</td></tr>
            <tr><td>K-Fold Test Score</td><td>0.8370950888192269</td></tr>
        </table>

        Gradient Boosting Results 
        <table>
            <tr><th colspan="2">Gradient Boosting</th></tr>
            <tr><td>Train Score (Mean Accuracy)</td><td>0.9487179487179487</td></tr>
            <tr><td>Test Score (Mean Accuracy)</td><td>0.8693181818181818</td></tr>
            <tr><td>Mean Squared Error</td><td>0.13068181818181818</td></tr>
            <tr><td>K-Fold Train Score</td><td>0.9383702731680776</td></tr>
            <tr><td>K-Fold Test Score</td><td>0.8336729362591433</td></tr>
        </table>
    </div>

    <div class="table-container">
        Random Forest Classifier Report
        <table border="1">
            <tr><th colspan="5">Random Forest Classification Report</th></tr>
            <tr><th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th></tr>
            <tr><td>0 (No Risk)</td><td>0.87</td><td>0.97</td><td>0.92</td><td>141</td></tr>
            <tr><td>1 (At Risk)</td><td>0.78</td><td>0.40</td><td>0.53</td><td>35</td></tr>
            <tr><td>Macro Avg</td><td>0.82</td><td>0.69</td><td>0.72</td><td>176</td></tr>
            <tr><td>Weighted Avg</td><td>0.85</td><td>0.86</td><td>0.84</td><td>176</td></tr>
            <tr><td>Accuracy</td><td colspan="4">0.86 (176 total)</td></tr>
        </table>
        
        Logistic Regression Classification Report 
        <table border="1">
            <tr><th colspan="5">Logistic Regression Classification Report</th></tr>
            <tr><th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th></tr>
            <tr><td>0 (No Risk)</td><td>0.81</td><td>0.99</td><td>0.89</td><td>141</td></tr>
            <tr><td>1 (At Risk)</td><td>0.60</td><td>0.09</td><td>0.15</td><td>35</td></tr>
            <tr><td>Macro Avg</td><td>0.71</td><td>0.54</td><td>0.52</td><td>176</td></tr>
            <tr><td>Weighted Avg</td><td>0.77</td><td>0.81</td><td>0.74</td><td>176</td></tr>
            <tr><td>Accuracy</td><td colspan="4">0.81 (176 total)</td></tr>
        </table>
    
        Gradient Boosting Classification Report
        <table border="1">
            <tr><th colspan="5">Gradient Boosting Classifier Classification Report</th></tr>
            <tr><th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th></tr>
            <tr><td>0 (No Risk)</td><td>0.88</td><td>0.97</td><td>0.92</td><td>141</td></tr>
            <tr><td>1 (At Risk)</td><td>0.80</td><td>0.46</td><td>0.58</td><td>35</td></tr>
            <tr><td>Macro Avg</td><td>0.84</td><td>0.71</td><td>0.75</td><td>176</td></tr>
            <tr><td>Weighted Avg</td><td>0.86</td><td>0.87</td><td>0.85</td><td>176</td></tr>
            <tr><td>Accuracy</td><td colspan="4">0.87 (176 total)</td></tr>
        </table>
    </div>
    
    <p class="centered-paragraph">
        The results indicate classification to be the better approach. Predicting an exact sink percentage is simply too unrealistic and 
        arguably not very valuable in a real world setting. The best classifier, currently, the the gradient boosting classifier with a 
        recall score of 0.46 for at risk convoys and a precision score of 0.88 for no risk convoys. These two metrics, I deem, are the most
        import in protecting convoys. My aim is the maximize the number of true positives for convoys at risk and minimize the number false positives
        for convoys at no risk. In the real world context of convoys, lives, ships, and cargo at are stake and thus, correctly predicting convoys at 
        risk is the most important. The instances of false positives for convoys at risk (precision for at risk), although not ideal, lends to
        a level of caution in protecting convoys. If a convoy may be at risk, than, I believe, it is better to classify it as an at risk convoy
        than not as a precautionary measure. Although, in the real world, this approach may be limited/unrealistic if a finite number of resources
        (escort ships, air-cover, etc) can be allocated to convoys and thus only convoys truly at risk can afford to have more protection resources. 
        Regardless, precision and recall for convoys at risk and not a risk will be optimized in further refinements of the classifiers. The link 
        to the code for all of the results above (regressors and classifications) can be found 
        <a href="https://github.com/MAP9900/Modeling-The-Convoy-System/blob/main/Code/Machine%20Learning/Convoy_Model_2.ipynb" target="_blank">here</a>. <br>
        
    </p> -->







    <!-- Old gb_grid and Xgboost results (Archive)-->

    <!-- <div class="table-container">
        <table>
            <tr><th colspan="2">Gradient Boosting Evaluation</th></tr>
            <tr><td>ROC AUC Score</td><td>0.7955</td></tr>
            <tr><td>Matthews Correlation Coefficient (MCC)</td><td>0.4605</td></tr>
            <tr><td>Balanced Accuracy</td><td>0.6930</td></tr>
            <tr><td>Recall (positive=1)</td><td>0.4400</td></tr>
            <tr><td>F2 Score</td><td>0.4741</td></tr>
            <tr><td>False Negatives</td><td>28</td></tr>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>Gradient Boosting Classification Report</caption>
            <thead>
                <tr>
                    <th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0 (No Risk)</td><td>0.86</td><td>0.95</td><td>0.90</td><td>185</td></tr>
                <tr><td>1 (At Risk)</td><td>0.69</td><td>0.44</td><td>0.54</td><td>50</td></tr>
                <tr><td>Macro Avg</td><td>0.77</td><td>0.69</td><td>0.72</td><td>235</td></tr>
                <tr><td>Weighted Avg</td><td>0.82</td><td>0.84</td><td>0.82</td><td>235</td></tr>
                <tr><td>Accuracy</td><td colspan="4">0.84</td></tr>
            </tbody>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>Gradient Boosting Threshold Comparison</caption>
            <thead>
                <tr>
                    <th>Threshold</th><th>Recall</th><th>Precision</th><th>False Negatives</th><th>F1-Score</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0.00</td><td>1.00</td><td>0.2128</td><td>0</td><td>0.1754</td></tr>
                <tr><td>0.05</td><td>0.82</td><td>0.3761</td><td>9</td><td>0.6341</td></tr>
                <tr><td>0.10</td><td>0.74</td><td>0.4512</td><td>13</td><td>0.6945</td></tr>
                <tr><td>0.20</td><td>0.64</td><td>0.5517</td><td>18</td><td>0.7355</td></tr>
                <tr><td>0.50</td><td>0.44</td><td>0.6875</td><td>28</td><td>0.7193</td></tr>
                <tr><td>0.95</td><td>0.14</td><td>0.7778</td><td>43</td><td>0.5639</td></tr>
            </tbody>
        </table>
    </div>
    <p class="centered-paragraph">
       ____
    </p>
    
    -->


    <!-- XGBoost Classifier Detailed Results -->
    <!-- <h2 style="text-align: center;">XGBoost Classifier Results</h2>
    <div class="table-container">
        <table>
            <tr><th colspan="2">XGBoost Evaluation</th></tr>
            <tr><td>ROC AUC Score</td><td>0.8082</td></tr>
            <tr><td>Matthews Correlation Coefficient (MCC)</td><td>0.4937</td></tr>
            <tr><td>Balanced Accuracy</td><td>0.7735</td></tr>
            <tr><td>Recall (positive=1)</td><td>0.7200</td></tr>
            <tr><td>F2 Score</td><td>0.6716</td></tr>
            <tr><td>False Negatives</td><td>14</td></tr>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>XGBoost Classification Report</caption>
            <thead>
                <tr>
                    <th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0 (No Risk)</td><td>0.92</td><td>0.83</td><td>0.87</td><td>185</td></tr>
                <tr><td>1 (At Risk)</td><td>0.53</td><td>0.72</td><td>0.61</td><td>50</td></tr>
                <tr><td>Macro Avg</td><td>0.72</td><td>0.77</td><td>0.74</td><td>235</td></tr>
                <tr><td>Weighted Avg</td><td>0.83</td><td>0.80</td><td>0.81</td><td>235</td></tr>
                <tr><td>Accuracy</td><td colspan="4">0.80</td></tr>
            </tbody>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>XGBoost Threshold Comparison</caption>
            <thead>
                <tr>
                    <th>Threshold</th><th>Recall</th><th>Precision</th><th>False Negatives</th><th>F1-Score</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0.00</td><td>1.00</td><td>0.2128</td><td>0</td><td>0.1754</td></tr>
                <tr><td>0.10</td><td>0.94</td><td>0.2423</td><td>3</td><td>0.3608</td></tr>
                <tr><td>0.25</td><td>0.86</td><td>0.3282</td><td>7</td><td>0.5732</td></tr>
                <tr><td>0.40</td><td>0.72</td><td>0.4800</td><td>14</td><td>0.7112</td></tr>
                <tr><td>0.55</td><td>0.64</td><td>0.5614</td><td>18</td><td>0.7398</td></tr>
                <tr><td>0.95</td><td>0.04</td><td>0.6667</td><td>48</td><td>0.4790</td></tr>
            </tbody>
        </table>
    </div>
    <p class="centered-paragraph">
        _____
    </p> -->
