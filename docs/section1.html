<!--Convoy Machine Learning    -->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Convoy Machine Learning</title>
    <link rel="stylesheet" href="styles.css"> <!-- Link to external CSS file -->
</head>
<body>
    
    <!-- Header Section -->
    <header>
        <h1>Convoy Machine Learning</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li> <!-- Link back to homepage -->
                <li><a href="section6.html">Results</a></li> <!-- Link to Section 6 Page -->
                <li><a href="section2.html">Convoy Data Visualization</a></li> <!-- Link to Section 2 Page -->
                <li><a href="section3.html">Convoy History</a></li> <!-- Link to Section 3 Page -->
                <li><a href="section4.html">Original Project</a></li> <!-- Link to Section 4 Page -->
                <li><a href="section5.html">Additional Info</a></li> <!-- Link to Section 5 Page -->
            </ul>
        </nav>
    </header>

    <main>
        
<!-- Original Classification Results -->
        <h2 style="text-align: center;"> </strong>Exploring Classification Algorithms</h2>
        <p class="centered-paragraph">
        

        Early experiments utilized a regression approach to predict exact sink percentages. The results for these initial attempts 
        can be found <a href="section1_1.html">here.</a> The limited data, wide variability, and unmodeled factors, however, made this
        approach unsuitable for the problem. Exact sink percentages of each convoy proved impossible to predict within the scope
        of the project. Instead, sink percentages were converted to binary values of 0 (no ships sunk) or 1 (at least one ship sunk). 
        This new method, based on classification, aims to alleviate the complexity of predicting an exact sink percentage while also
        providing a more realistic approach of identifying high-risk convoys. Various algorithms were tested to determine the one 
        best suited for the challenge.
        </p>
        
        <div class="table-container">
            <table>
                <caption>Classification Algorithm Comparison:</caption>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Acc</th>
                        <th>ROC_AUC</th>
                        <th>MCC</th>
                        <th>Bal_Acc</th>
                        <th>Recall1</th>
                        <th>F1_1</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>LogisticRegression</td><td>0.79</td><td>0.786</td><td>0.193</td><td>0.554</td><td>0.14</td><td>0.22</td></tr>
                    <tr><td>SGDClassifier</td><td>0.79</td><td>0.728</td><td>0.148</td><td>0.537</td><td>0.10</td><td>0.17</td></tr>
                    <tr><td>LinearSVC</td><td>0.79</td><td>0.535</td><td>0.000</td><td>0.500</td><td>0.00</td><td>0.00</td></tr>
                    <tr><td>SVC</td><td>0.80</td><td>0.768</td><td>0.215</td><td>0.545</td><td>0.10</td><td>0.18</td></tr>
                    <tr><td>NuSVC</td><td>0.77</td><td>0.667</td><td>0.241</td><td>0.606</td><td>0.32</td><td>0.37</td></tr>
                    <tr><td>KNeighborsClassifier</td><td>0.80</td><td>0.740</td><td>0.265</td><td>0.588</td><td>0.22</td><td>0.32</td></tr>
                    <tr><td>RadiusNeighborsClassifier</td><td>0.78</td><td>0.567</td><td>-0.034</td><td>0.497</td><td>0.00</td><td>0.00</td></tr>
                    <tr><td>DecisionTreeClassifier</td><td>0.74</td><td>0.621</td><td>0.235</td><td>0.621</td><td>0.42</td><td>0.40</td></tr>
                    <tr><td>RandomForestClassifier</td><td>0.84</td><td>0.815</td><td>0.461</td><td>0.674</td><td>0.38</td><td>0.51</td></tr>
                    <tr><td>ExtraTreesClassifier</td><td>0.84</td><td>0.791</td><td>0.469</td><td>0.688</td><td>0.42</td><td>0.53</td></tr>
                    <tr><td>BaggingClassifier</td><td>0.83</td><td>0.766</td><td>0.400</td><td>0.656</td><td>0.36</td><td>0.47</td></tr>
                    <tr class="highlight-row"><td>GradientBoostingClassifier</td><td>0.84</td><td>0.835</td><td>0.473</td><td>0.696</td><td>0.44</td><td>0.54</td></tr>
                    <tr><td>AdaBoostClassifier</td><td>0.82</td><td>0.790</td><td>0.368</td><td>0.631</td><td>0.30</td><td>0.42</td></tr>
                    <tr><td>GaussianNB</td><td>0.77</td><td>0.670</td><td>0.096</td><td>0.530</td><td>0.12</td><td>0.18</td></tr>
                    <tr><td>BernoulliNB</td><td>0.79</td><td>0.699</td><td>0.000</td><td>0.500</td><td>0.00</td><td>0.00</td></tr>
                    <tr><td>ComplementNB</td><td>0.49</td><td>0.555</td><td>0.061</td><td>0.537</td><td>0.62</td><td>0.34</td></tr>
                    <tr><td>LinearDiscriminantAnalysis</td><td>0.79</td><td>0.787</td><td>0.205</td><td>0.561</td><td>0.16</td><td>0.25</td></tr>
                    <tr><td>QuadraticDiscriminantAnalysis</td><td>0.78</td><td>0.790</td><td>0.425</td><td>0.735</td><td>0.66</td><td>0.56</td></tr>
                    <tr><td>MLPClassifier</td><td>0.67</td><td>0.542</td><td>-0.064</td><td>0.471</td><td>0.12</td><td>0.13</td></tr>
                </tbody>
            </table>
        </div>
        <p class="centered-paragraph">
        The Gradient Boosting Classifier performs the best on this data and will be the foundation for all future tests. 
        Notably, the RandomForestClassifier, QuadraticDiscriminantAnalysis, and ComplementNB algorithms performed comparable, even resulting in higher 
        recall scores. However, ComplementNB is an algorithm developed for text classification and is best suited for imbalanced
        and discrete datasets. Tests done in this 
        <a href="https://github.com/MAP9900/Convoy-Predictor-Project/blob/main/notebooks/exploration/CNB_and_QDA_Test.ipynb" target="_blank">notebook</a>
        reveal the ComplementNB algorithm fails to produce meaningful results. The model results in near binary behavior; 
        at low thresholds everything is classified as positive and at high thresholds, everything is classified as negative. 
        Other Gradient Boosting algorithms from the XGBoost library will be tested next. These results are below.


        </p>

        <div class="table-container">
            <table>
                <caption>Gradient Boosting Family Comparison:</caption>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Acc</th>
                        <th>ROC_AUC</th>
                        <th>MCC</th>
                        <th>Bal_Acc</th>
                        <th>Recall1</th>
                        <th>F1_1</th>
                    </tr>
                </thead>
                <tbody>
                    <tr class="highlight-row"><td>GradientBoostingClassifier</td><td>0.84</td><td>0.835</td><td>0.473</td><td>0.696</td><td>0.44</td><td>0.54</td></tr>
                    <tr><td>XGBClassifier</td><td>0.83</td><td>0.773</td><td>0.408</td><td>0.651</td><td>0.34</td><td>0.46</td></tr>
                    <tr><td>LGBMClassifier</td><td>0.83</td><td>0.792</td><td>0.443</td><td>0.683</td><td>0.42</td><td>0.52</td></tr>
                    <tr><td>CatBoostClassifier</td><td>0.84</td><td>0.832</td><td>0.457</td><td>0.659</td><td>0.34</td><td>0.48</td></tr>
                </tbody>
            </table>
        </div>

        <p class="centered-paragraph">
            The standard Scikit-Learn Gradient Boosting model outperforms the other boosted tree variants, achieving the highest 
            ROC-AUC and F1 scores along with the strongest recall for at-risk convoys. Further optimization will focus on 
            improving recall and reducing false negatives. The emphasis on recall (true positives divided by true positives plus 
            false negatives) is necessary because identifying convoys at risk is more important than identifying those not at risk.
            False negative (cases where the model predicts a convoy is not at risk when it actually is) are particularly dangerous, 
            especially with human life and vital wartime supplies at stake. False positives, while not ideal, carry much less
            associated risk. If a convoy is labeled as at risk but in reality is not, no harm results. There are limitations to
            false negatives, such as the need to allocate defensive resources as otherwise, every convoy could simply be labeled at risk.
            However, some false positives are acceptable as a form of caution.
        </p>

        <!-- Gradient Boosting Classifier Detailed Results -->



    <h2 style="text-align: center;">Optimizing the Gradient Boosting Model and Comparing Thresholds</h2>

     <p class="centered-paragraph">
        To optimize the gradient boosting classifier, Grid Search Cross Validation will be used to test a predefined set of hyperparameters. The hyperparameters 
        optimized are learning_rate, n_estimators, max_depth, min_samples_leaf, min_samples_split, subsample, and max_features. To learn more about these hyperparameters
        see Scikit-Learn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" target="_blank">docs</a>. 
        After Gris Search CV, a threshold comparison is done to examine the affect on recall, precision, and accuracy. Threshold, which defaults to 0.5, is the value used to 
        convert the model's probability output into a discrete class (0 or 1). With the default value of 0.5, any output below 0.5 will be classified as 0 and above 0.5, will be a 1.
        By manipulating the threshold, more weight can be onto recall and limiting the number of false negatives at the expense of decreasing precision and increasing the number of
        false positives. The results for the optimized classifier and threshold comparison are below. 

        </p>
        <br>
        <section class="table-section">
            <!-- <h3>Threshold Comparison</h3> -->
            <div class="table-block table-pair">
                <table>
                    <caption>Optimized GB Classifier Threshold Comparison (0.00 – 0.50)</caption>
                    <thead>
                        <tr>
                            <th>Threshold</th>
                            <th>Recall</th>
                            <th>Precision</th>
                            <th>False Negatives</th>
                            <th>Accuracy</th>
                            <th>F1-Score</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>0.00</td><td>1.00</td><td>0.212766</td><td>0</td><td>0.212766</td><td>0.175439</td></tr>
                        <tr><td>0.05</td><td>0.86</td><td>0.361345</td><td>7</td><td>0.646809</td><td>0.616564</td></tr>
                        <tr><td>0.10</td><td>0.80</td><td>0.449438</td><td>10</td><td>0.748936</td><td>0.698646</td></tr>
                        <tr><td>0.15</td><td>0.72</td><td>0.480000</td><td>14</td><td>0.774468</td><td>0.711188</td></tr>
                        <tr><td>0.20</td><td>0.68</td><td>0.523077</td><td>16</td><td>0.800000</td><td>0.729455</td></tr>
                        <tr><td>0.25</td><td>0.64</td><td>0.551724</td><td>18</td><td>0.812766</td><td>0.735523</td></tr>
                        <tr><td>0.30</td><td>0.64</td><td>0.592593</td><td>18</td><td>0.829787</td><td>0.753047</td></tr>
                        <tr><td>0.35</td><td>0.60</td><td>0.600000</td><td>20</td><td>0.829787</td><td>0.745946</td></tr>
                        <tr><td>0.40</td><td>0.54</td><td>0.600000</td><td>23</td><td>0.825532</td><td>0.729544</td></tr>
                        <tr><td>0.45</td><td>0.46</td><td>0.575000</td><td>27</td><td>0.812766</td><td>0.697661</td></tr>
                        <tr><td>0.50</td><td>0.42</td><td>0.567568</td><td>29</td><td>0.808511</td><td>0.682633</td></tr>
                    </tbody>
                </table>
                <table>
                    <caption>Optimized GB Classifier Threshold Comparison (0.55 – 1.00)</caption>
                    <thead>
                        <tr>
                            <th>Threshold</th>
                            <th>Recall</th>
                            <th>Precision</th>
                            <th>False Negatives</th>
                            <th>Accuracy</th>
                            <th>F1-Score</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>0.55</td><td>0.40</td><td>0.555556</td><td>30</td><td>0.804255</td><td>0.672662</td></tr>
                        <tr><td>0.60</td><td>0.36</td><td>0.620690</td><td>32</td><td>0.817021</td><td>0.672861</td></tr>
                        <tr><td>0.65</td><td>0.34</td><td>0.653846</td><td>33</td><td>0.821277</td><td>0.670385</td></tr>
                        <tr><td>0.70</td><td>0.32</td><td>0.640000</td><td>34</td><td>0.817021</td><td>0.658903</td></tr>
                        <tr><td>0.75</td><td>0.32</td><td>0.695652</td><td>34</td><td>0.825532</td><td>0.667541</td></tr>
                        <tr><td>0.80</td><td>0.30</td><td>0.714286</td><td>35</td><td>0.825532</td><td>0.659889</td></tr>
                        <tr><td>0.85</td><td>0.24</td><td>0.705882</td><td>38</td><td>0.817021</td><td>0.625755</td></tr>
                        <tr><td>0.90</td><td>0.14</td><td>0.700000</td><td>43</td><td>0.804255</td><td>0.560569</td></tr>
                        <tr><td>0.95</td><td>0.12</td><td>0.857143</td><td>44</td><td>0.808511</td><td>0.550784</td></tr>
                        <tr><td>1.00</td><td>0.00</td><td>0.000000</td><td>50</td><td>0.787234</td><td>0.440476</td></tr>
                    </tbody>
                </table>
            </div>
        </section>

        <figure>
                <h4>Visualization of Different Thresholds</h4>
                <img src="images/Optimized_GB_Threshold_Results.png" alt="Visualization of Different Thresholds" width="750" height="500">
                <!-- <figcaption>____</figcaption> -->
            </figure>

     <p class="centered-paragraph">
        The threshold comparison results indicate a threshold interval of [0.25, 0.35] to be the best performing. At a threshold of 0.30, f1-score peaks at 
        0.75 and so does accuracy at 0.83 given the best balance between recall and precision. However, the number of false negatives remains relatively high
        at 18 convoys classified as not a risk despite having ships sunk. So a recall focused best interval for threshold is instead at [0.05, 0.15]. At this interval.
        false negatives are 7, 10, & 14 respectively. These results are more in line with goal of producing a model with a high recall score. Accuracy and f1-score 
        remain high at a threshold of 0.15 but quickly begin at thresholds of 0.10 and 0.05. Therefore, determining a single, optimal threshold is difficult with each value 
        having trade offs between the different metrics. A good balance, however, is a threshold of 0.20 which sees recall, accuracy and f1-score 
        remain high at 0.68, 0.80, & 0.73 respectively and only 16 false negatives occuring. 
     </p>
    
    <h2 style="text-align: center;">Exploring Other Promising Algorithms</h2>
    <p class="centered-paragraph">
        Prior tests and the results above indicate multiple algorithms with potential to produce strong results. These other
        models will now be optimized and tested to compare with the GradientBoostingClassifier. Then the best performing models
        will combined through ensemble learning. 
    </p>
    <h4 style="text-align: center;">Optimized Results</h4>
<!--TODO: Instead of testing just QuadraticDiscriminantAnalysis, optimize a few algorithms and then compare all the results. -->
<div class="table-container">
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th>Acc</th>
                <th>ROC_AUC</th>
                <th>MCC</th>
                <th>Bal_Acc</th>
                <th>Recall1</th>
                <th>F1_1</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>QuadraticDiscriminantAnalysis</td><td>0.60</td><td>0.790</td><td>0.334</td><td>0.702</td><td>0.88</td><td>0.48</td></tr>
        </tbody>
    </table>
</div>

<h4 style="text-align: center;">Threshold Comparison</h4>

<section class="table-section" style="margin-top: 1.5rem;">
    <div class="table-block table-pair" style="display: flex; gap: 1.5rem; justify-content: center; flex-wrap: wrap; font-size: 0.85rem;">
        <table style="flex: 1 1 320px; max-width: 480px;">
            <caption>ComplementNB Threshold Comparison</caption>
            <thead>
                <tr>
                    <th>Threshold</th>
                    <th>Recall</th>
                    <th>Precision</th>
                    <th>False Negatives</th>
                    <th>Accuracy</th>
                    <th>F1-Score</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0.00</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.05</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.10</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.15</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.20</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.25</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.30</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.35</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.40</td><td>1.00</td><td>0.215</td><td>0</td><td>0.221</td><td>0.187</td></tr>
                <tr><td>0.45</td><td>0.86</td><td>0.256</td><td>7</td><td>0.438</td><td>0.435</td></tr>
                <tr><td>0.50</td><td>0.60</td><td>0.326</td><td>20</td><td>0.651</td><td>0.586</td></tr>
                <tr class="highlight-row"><td>0.55</td><td>0.36</td><td>0.581</td><td>32</td><td>0.809</td><td>0.664</td></tr>
                <tr><td>0.60</td><td>0.06</td><td>0.600</td><td>47</td><td>0.791</td><td>0.496</td></tr>
                <tr><td>0.65</td><td>0.02</td><td>0.333</td><td>49</td><td>0.783</td><td>0.458</td></tr>
                <tr><td>0.70</td><td>0.00</td><td>0.000</td><td>50</td><td>0.783</td><td>0.439</td></tr>
                <tr><td>0.75</td><td>0.00</td><td>0.000</td><td>50</td><td>0.783</td><td>0.439</td></tr>
                <tr><td>0.80</td><td>0.00</td><td>0.000</td><td>50</td><td>0.783</td><td>0.439</td></tr>
                <tr><td>0.85</td><td>0.00</td><td>0.000</td><td>50</td><td>0.787</td><td>0.440</td></tr>
                <tr><td>0.90</td><td>0.00</td><td>0.000</td><td>50</td><td>0.787</td><td>0.440</td></tr>
                <tr><td>0.95</td><td>0.00</td><td>0.000</td><td>50</td><td>0.787</td><td>0.440</td></tr>
                <tr><td>1.00</td><td>0.00</td><td>0.000</td><td>50</td><td>0.787</td><td>0.440</td></tr>
            </tbody>
        </table>
        <table style="flex: 1 1 320px; max-width: 480px;">
            <caption>QuadraticDiscriminantAnalysis Threshold Comparison</caption>
            <thead>
                <tr>
                    <th>Threshold</th>
                    <th>Recall</th>
                    <th>Precision</th>
                    <th>False Negatives</th>
                    <th>Accuracy</th>
                    <th>F1-Score</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0.00</td><td>1.00</td><td>0.213</td><td>0</td><td>0.213</td><td>0.175</td></tr>
                <tr><td>0.05</td><td>0.90</td><td>0.296</td><td>5</td><td>0.523</td><td>0.514</td></tr>
                <tr><td>0.10</td><td>0.88</td><td>0.303</td><td>6</td><td>0.545</td><td>0.531</td></tr>
                <tr><td>0.15</td><td>0.88</td><td>0.324</td><td>6</td><td>0.583</td><td>0.564</td></tr>
                <tr><td>0.20</td><td>0.88</td><td>0.344</td><td>6</td><td>0.617</td><td>0.593</td></tr>
                <tr><td>0.25</td><td>0.86</td><td>0.368</td><td>7</td><td>0.655</td><td>0.624</td></tr>
                <tr><td>0.30</td><td>0.80</td><td>0.370</td><td>10</td><td>0.668</td><td>0.628</td></tr>
                <tr><td>0.35</td><td>0.80</td><td>0.400</td><td>10</td><td>0.702</td><td>0.657</td></tr>
                <tr><td>0.40</td><td>0.80</td><td>0.435</td><td>10</td><td>0.736</td><td>0.687</td></tr>
                <tr><td>0.45</td><td>0.70</td><td>0.449</td><td>15</td><td>0.753</td><td>0.689</td></tr>
                <tr><td>0.50</td><td>0.66</td><td>0.485</td><td>17</td><td>0.779</td><td>0.706</td></tr>
                <tr><td>0.55</td><td>0.56</td><td>0.528</td><td>22</td><td>0.800</td><td>0.708</td></tr>
                <tr><td>0.60</td><td>0.50</td><td>0.510</td><td>25</td><td>0.791</td><td>0.686</td></tr>
                <tr><td>0.65</td><td>0.46</td><td>0.511</td><td>27</td><td>0.791</td><td>0.677</td></tr>
                <tr><td>0.70</td><td>0.42</td><td>0.512</td><td>29</td><td>0.791</td><td>0.666</td></tr>
                <tr><td>0.75</td><td>0.34</td><td>0.500</td><td>33</td><td>0.787</td><td>0.638</td></tr>
                <tr><td>0.80</td><td>0.28</td><td>0.500</td><td>36</td><td>0.787</td><td>0.616</td></tr>
                <tr><td>0.85</td><td>0.22</td><td>0.579</td><td>39</td><td>0.800</td><td>0.601</td></tr>
                <tr class="highlight-row"><td>0.90</td><td>0.18</td><td>0.643</td><td>41</td><td>0.804</td><td>0.584</td></tr>
                <tr><td>0.95</td><td>0.10</td><td>0.556</td><td>45</td><td>0.791</td><td>0.525</td></tr>
                <tr><td>1.00</td><td>0.02</td><td>0.333</td><td>49</td><td>0.783</td><td>0.458</td></tr>
            </tbody>
        </table>
    </div>
</section>   
<p class="centered-paragraph"></p>



    </main>
    

    <!-- Footer Section -->
    <footer>
        <p>&copy; 2025 Matthew Plambeck</p>
    </footer>

</body>
</html>


<!-- Old HTML Code, used to reference how tables were made


    <-- Old gb_grid and Xgboost results (Archive)-->

    <!-- <div class="table-container">
        <table>
            <tr><th colspan="2">Gradient Boosting Evaluation</th></tr>
            <tr><td>ROC AUC Score</td><td>0.7955</td></tr>
            <tr><td>Matthews Correlation Coefficient (MCC)</td><td>0.4605</td></tr>
            <tr><td>Balanced Accuracy</td><td>0.6930</td></tr>
            <tr><td>Recall (positive=1)</td><td>0.4400</td></tr>
            <tr><td>F2 Score</td><td>0.4741</td></tr>
            <tr><td>False Negatives</td><td>28</td></tr>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>Gradient Boosting Classification Report</caption>
            <thead>
                <tr>
                    <th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0 (No Risk)</td><td>0.86</td><td>0.95</td><td>0.90</td><td>185</td></tr>
                <tr><td>1 (At Risk)</td><td>0.69</td><td>0.44</td><td>0.54</td><td>50</td></tr>
                <tr><td>Macro Avg</td><td>0.77</td><td>0.69</td><td>0.72</td><td>235</td></tr>
                <tr><td>Weighted Avg</td><td>0.82</td><td>0.84</td><td>0.82</td><td>235</td></tr>
                <tr><td>Accuracy</td><td colspan="4">0.84</td></tr>
            </tbody>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>Gradient Boosting Threshold Comparison</caption>
            <thead>
                <tr>
                    <th>Threshold</th><th>Recall</th><th>Precision</th><th>False Negatives</th><th>F1-Score</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0.00</td><td>1.00</td><td>0.2128</td><td>0</td><td>0.1754</td></tr>
                <tr><td>0.05</td><td>0.82</td><td>0.3761</td><td>9</td><td>0.6341</td></tr>
                <tr><td>0.10</td><td>0.74</td><td>0.4512</td><td>13</td><td>0.6945</td></tr>
                <tr><td>0.20</td><td>0.64</td><td>0.5517</td><td>18</td><td>0.7355</td></tr>
                <tr><td>0.50</td><td>0.44</td><td>0.6875</td><td>28</td><td>0.7193</td></tr>
                <tr><td>0.95</td><td>0.14</td><td>0.7778</td><td>43</td><td>0.5639</td></tr>
            </tbody>
        </table>
    </div>
    <p class="centered-paragraph">
       ____
    </p>
    
    -->


    <!-- XGBoost Classifier Detailed Results -->
    <!-- <h2 style="text-align: center;">XGBoost Classifier Results</h2>
    <div class="table-container">
        <table>
            <tr><th colspan="2">XGBoost Evaluation</th></tr>
            <tr><td>ROC AUC Score</td><td>0.8082</td></tr>
            <tr><td>Matthews Correlation Coefficient (MCC)</td><td>0.4937</td></tr>
            <tr><td>Balanced Accuracy</td><td>0.7735</td></tr>
            <tr><td>Recall (positive=1)</td><td>0.7200</td></tr>
            <tr><td>F2 Score</td><td>0.6716</td></tr>
            <tr><td>False Negatives</td><td>14</td></tr>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>XGBoost Classification Report</caption>
            <thead>
                <tr>
                    <th></th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0 (No Risk)</td><td>0.92</td><td>0.83</td><td>0.87</td><td>185</td></tr>
                <tr><td>1 (At Risk)</td><td>0.53</td><td>0.72</td><td>0.61</td><td>50</td></tr>
                <tr><td>Macro Avg</td><td>0.72</td><td>0.77</td><td>0.74</td><td>235</td></tr>
                <tr><td>Weighted Avg</td><td>0.83</td><td>0.80</td><td>0.81</td><td>235</td></tr>
                <tr><td>Accuracy</td><td colspan="4">0.80</td></tr>
            </tbody>
        </table>
    </div>

    <div class="table-container">
        <table>
            <caption>XGBoost Threshold Comparison</caption>
            <thead>
                <tr>
                    <th>Threshold</th><th>Recall</th><th>Precision</th><th>False Negatives</th><th>F1-Score</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>0.00</td><td>1.00</td><td>0.2128</td><td>0</td><td>0.1754</td></tr>
                <tr><td>0.10</td><td>0.94</td><td>0.2423</td><td>3</td><td>0.3608</td></tr>
                <tr><td>0.25</td><td>0.86</td><td>0.3282</td><td>7</td><td>0.5732</td></tr>
                <tr><td>0.40</td><td>0.72</td><td>0.4800</td><td>14</td><td>0.7112</td></tr>
                <tr><td>0.55</td><td>0.64</td><td>0.5614</td><td>18</td><td>0.7398</td></tr>
                <tr><td>0.95</td><td>0.04</td><td>0.6667</td><td>48</td><td>0.4790</td></tr>
            </tbody>
        </table>
    </div>
    <p class="centered-paragraph">
        _____
    </p> -->

<!-- FIGURE PAIR EXAMPLE:
<div class="figure-pair" style="display: flex; gap: 0rem; justify-content: center; flex-wrap: wrap; margin-top: 1.5rem;">
    <figure style="flex: 1 1 320px; max-width: 480px;">
        <img src="images/CNB_Confusion_Matrix.png" alt="CNB CM" style="width: 100%; height: auto;">
    </figure>
    <figure style="flex: 1 1 320px; max-width: 480px;">
        <img src="images/QDA_Confusion_Matrix.png" alt="QDA CM" style="width: 100%; height: auto;">
    </figure>
</div> -->