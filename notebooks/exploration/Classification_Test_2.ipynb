{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0874c833",
   "metadata": {},
   "source": [
    "**Testing Gradient_Boosting_Optimization.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84debad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os, random\n",
    "import importlib\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#Class Import\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\"))) #Allow for imports from src\n",
    "from src.models import Gradient_Boosting_Optimization\n",
    "importlib.reload(Gradient_Boosting_Optimization) #Ensures file is uptodate!\n",
    "from src.models.Gradient_Boosting_Optimization import Gradient_Boosting_Optimization\n",
    "\n",
    "#Set Seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"1945\"\n",
    "random.seed(1945)\n",
    "np.random.seed(1945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecc6406c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 21)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Complied data of convoys\n",
    "#Routes examined are HX, SC, OB, ON, ONS\n",
    "df = pd.read_csv('/Users/matthewplambeck/Desktop/Convoy Predictor/data/processed/Complete_Convoy_Data.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.shape #Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a00a2556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Ships</th>\n",
       "      <th>Number of Escort Ships</th>\n",
       "      <th>Number of Stragglers</th>\n",
       "      <th>Total Tons of Convoy</th>\n",
       "      <th>Overall Sink Percentage</th>\n",
       "      <th>Avg Number of U-Boats in Atlantic</th>\n",
       "      <th>Escort Ratio</th>\n",
       "      <th>Time At Sea (Days)</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Previous Month Avg Sink %</th>\n",
       "      <th>Approx. Sighting Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22877.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22967.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.434062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Ships  Number of Escort Ships  Number of Stragglers  \\\n",
       "0              5.0                     2.0                   0.0   \n",
       "1              5.0                     2.0                   0.0   \n",
       "2              7.0                     4.0                   0.0   \n",
       "\n",
       "   Total Tons of Convoy  Overall Sink Percentage  \\\n",
       "0               22877.0                      0.0   \n",
       "1               22967.0                      0.0   \n",
       "2               21293.0                      0.0   \n",
       "\n",
       "   Avg Number of U-Boats in Atlantic  Escort Ratio  Time At Sea (Days)  Month  \\\n",
       "0                                6.0      0.400000                 3.0    9.0   \n",
       "1                                6.0      0.400000                 5.0    9.0   \n",
       "2                                6.0      0.571429                 5.0    9.0   \n",
       "\n",
       "     Year  Previous Month Avg Sink %  Approx. Sighting Range  \n",
       "0  1939.0                        0.0               12.190200  \n",
       "1  1939.0                        0.0               12.190200  \n",
       "2  1939.0                        0.0               14.434062  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop unecessary/redundent features\n",
    "df = df.drop(columns=['Convoy Number', 'Number of Ships Sunk', 'Depart_Date', 'Arrival/Dispersal Date', 'Number of Escorts Sunk', \\\n",
    "                         'Number of Stragglers Sunk', 'Total Tons of Ships Sunk', 'Escort Sink Percentage', 'Straggler Sink Percentage'])\n",
    "df.reset_index(drop=True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db3ec034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Overall Sink Percentage to binary 1( High)\n",
    "df['Risk'] = (df['Overall Sink Percentage'] > 0).astype(int) \n",
    "#Risk is binary based off whether a ship was sunk while in a convoy:  (0 = No Ships Sunk, 1 = At Least One Ship Sunk)\n",
    "X = np.array(df.drop(columns=['Overall Sink Percentage', 'Risk'])) #Remove Overall Sink Percentage as it leaks data\n",
    "y = df['Risk'].values #Prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be737493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_params = {\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"n_estimators\": [150, 300],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"min_samples_leaf\": [1, 5]}\n",
    "\n",
    "optimizer = Gradient_Boosting_Optimization(\n",
    "    model=GradientBoostingClassifier(random_state=1945),\n",
    "    parameter_grid=gb_params,\n",
    "    cv_folds=5,\n",
    "    positive_label=1,\n",
    "    optimize_scoring=\"recall\",\n",
    "    auto_calibrate_threshold=True,\n",
    "    threshold_beta=2.0,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c7a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Score: 0.9212 ± 0.0059\n",
      "Average Test Score: 0.8073 ± 0.0319\n"
     ]
    }
   ],
   "source": [
    "#Train Test Split\n",
    "optimizer.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "train_scores, test_scores = optimizer.k_folds(stratified=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bde9dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters Found:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 150, 'subsample': 0.8}\n",
      "Best Cross-Validation Score: 0.4230\n"
     ]
    }
   ],
   "source": [
    "#Optimize\n",
    "optimizer.optimize(scoring=None, fit_params={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6528f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied custom decision threshold: 0.350\n",
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       185\n",
      "           1       0.56      0.50      0.53        50\n",
      "\n",
      "    accuracy                           0.81       235\n",
      "   macro avg       0.71      0.70      0.70       235\n",
      "weighted avg       0.80      0.81      0.80       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7830\n",
      "Matthews Correlation Coefficient (MCC): 0.4076\n",
      "Balanced Accuracy: 0.6959\n",
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0          165           20\n",
      "Actual 1           25           25\n",
      "Recall (positive=1): 0.5000\n",
      "F2 Score: 0.5102\n",
      "False Negatives: 25\n",
      "GradientBoostingClassifier Confusion Matrix (values only):\n",
      "[[165  20]\n",
      " [ 25  25]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5102040816326531, 0.35)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate\n",
    "results = optimizer.evaluate(show_plots=False)\n",
    "results[\"recall\"], results[\"f2_score\"], results[\"decision_threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d59c60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied custom decision threshold: 0.350\n",
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       185\n",
      "           1       0.56      0.50      0.53        50\n",
      "\n",
      "    accuracy                           0.81       235\n",
      "   macro avg       0.71      0.70      0.70       235\n",
      "weighted avg       0.80      0.81      0.80       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7830\n",
      "Matthews Correlation Coefficient (MCC): 0.4076\n",
      "Balanced Accuracy: 0.6959\n",
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0          165           20\n",
      "Actual 1           25           25\n",
      "Recall (positive=1): 0.5000\n",
      "F2 Score: 0.5102\n",
      "False Negatives: 25\n",
      "GradientBoostingClassifier Confusion Matrix (values only):\n",
      "[[165  20]\n",
      " [ 25  25]]\n"
     ]
    }
   ],
   "source": [
    "optimizer.set_decision_threshold(0.35) #Test manual threshold for compairson\n",
    "threshold_results = optimizer.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00948ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 320 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n320 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/xgboost/core.py\", line 705, in inner_f\n    return func(**kwargs)\nTypeError: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m\n\u001b[1;32m     10\u001b[0m xgb_optimizer \u001b[38;5;241m=\u001b[39m Gradient_Boosting_Optimization(\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39mXGBClassifier(\n\u001b[1;32m     12\u001b[0m         objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     auto_calibrate_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     threshold_beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m,)\n\u001b[1;32m     23\u001b[0m xgb_optimizer\u001b[38;5;241m.\u001b[39mtrain_test_split(X, y, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1945\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mxgb_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxgb_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mearly_stopping_rounds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m xgb_results \u001b[38;5;241m=\u001b[39m xgb_optimizer\u001b[38;5;241m.\u001b[39mevaluate(show_plots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Convoy Predictor/src/models/Gradient_Boosting_Optimization.py:231\u001b[0m, in \u001b[0;36mGradient_Boosting_Optimization.optimize\u001b[0;34m(self, scoring, fit_params)\u001b[0m\n\u001b[1;32m    229\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_folds, scoring\u001b[38;5;241m=\u001b[39mscoring_to_use, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m#n_jobs = -1 uses all available CPUs (Parallel Execution). Switch to -2 to avoid freezing (ex: running server side)\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Hyperparameters Found:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1028\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m   1026\u001b[0m     )\n\u001b[0;32m-> 1028\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:505\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    499\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 320 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n320 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/Caskroom/miniforge/base/envs/Python-ML/lib/python3.10/site-packages/xgboost/core.py\", line 705, in inner_f\n    return func(**kwargs)\nTypeError: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'\n"
     ]
    }
   ],
   "source": [
    "#TODO Fix this\n",
    "xgb_params = {\n",
    "    \"eta\": [0.05, 0.1],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 1.0],\n",
    "    \"gamma\": [0, 1],\n",
    "    \"scale_pos_weight\": [1, 3],}\n",
    "\n",
    "xgb_optimizer = Gradient_Boosting_Optimization(\n",
    "    model=XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        use_label_encoder=False,\n",
    "        random_state=1945,\n",
    "        n_estimators=500),\n",
    "    parameter_grid=xgb_params,\n",
    "    positive_label=1,\n",
    "    optimize_scoring=\"recall\",\n",
    "    auto_calibrate_threshold=True,\n",
    "    threshold_beta=2.0,)\n",
    "\n",
    "xgb_optimizer.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "xgb_optimizer.optimize(\n",
    "    fit_params={\n",
    "        \"eval_set\": [(xgb_optimizer.X_test, xgb_optimizer.y_test)],\n",
    "        \"early_stopping_rounds\": 25,\n",
    "        \"verbose\": False,})\n",
    "xgb_results = xgb_optimizer.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de08c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old Results (Tested in Algorithm_Test_2 Notebook)\n",
    "# GradientBoostingClassifier Evaluation:\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.86      0.95      0.90       185\n",
    "#            1       0.71      0.44      0.54        50\n",
    "\n",
    "#     accuracy                           0.84       235\n",
    "#    macro avg       0.79      0.70      0.72       235\n",
    "# weighted avg       0.83      0.84      0.83       235\n",
    "\n",
    "\n",
    "# ROC AUC Score: 0.8351\n",
    "# Matthews Correlation Coefficient (MCC): 0.4733\n",
    "# Balanced Accuracy: 0.6957\n",
    "# GradientBoostingClassifier Confusion Matrix (values only):\n",
    "# [[176   9]\n",
    "#  [ 28  22]]\n",
    "\n",
    "#New Results from above:\n",
    "\n",
    "# Applied custom decision threshold: 0.350\n",
    "\n",
    "# GradientBoostingClassifier Evaluation:\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.87      0.89      0.88       185\n",
    "#            1       0.56      0.50      0.53        50\n",
    "\n",
    "#     accuracy                           0.81       235\n",
    "#    macro avg       0.71      0.70      0.70       235\n",
    "# weighted avg       0.80      0.81      0.80       235\n",
    "\n",
    "\n",
    "# ROC AUC Score: 0.7830\n",
    "# Matthews Correlation Coefficient (MCC): 0.4076\n",
    "# Balanced Accuracy: 0.6959\n",
    "# Confusion Matrix:\n",
    "#           Predicted 0  Predicted 1\n",
    "# Actual 0          165           20\n",
    "# Actual 1           25           25\n",
    "# Recall (positive=1): 0.5000\n",
    "# F2 Score: 0.5102\n",
    "# False Negatives: 25\n",
    "# GradientBoostingClassifier Confusion Matrix (values only):\n",
    "# [[165  20]\n",
    "#  [ 25  25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d5c14",
   "metadata": {},
   "source": [
    "**Further Testing as Results did not improve as I had hoped :(**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74527382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       185\n",
      "           1       0.71      0.44      0.54        50\n",
      "\n",
      "    accuracy                           0.84       235\n",
      "   macro avg       0.79      0.70      0.72       235\n",
      "weighted avg       0.83      0.84      0.83       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8351\n",
      "Matthews Correlation Coefficient (MCC): 0.4733\n",
      "Balanced Accuracy: 0.6957\n",
      "GradientBoostingClassifier Confusion Matrix (values only):\n",
      "[[176   9]\n",
      " [ 28  22]]\n",
      "Legacy recall: 0.44\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Baseline ML_Class_1\n",
    "\n",
    "#Class Import\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\"))) #Allow for imports from src\n",
    "from src.models import ML_Class_1\n",
    "importlib.reload(ML_Class_1) #Ensures file is uptodate!\n",
    "from src.models.ML_Class_1 import Model_Tester as LegacyTester\n",
    "\n",
    "legacy = LegacyTester(\n",
    "    model=GradientBoostingClassifier(random_state=1945),\n",
    "    parameter_grid=None,\n",
    "    cv_folds=5)\n",
    "\n",
    "legacy.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "legacy.optimize()  #no grid search\n",
    "legacy_results = legacy.evaluate(show_plots=False)\n",
    "print(\"Legacy recall:\", legacy_results[\"classification_report\"][\"1\"][\"recall\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2447bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       185\n",
      "           1       0.71      0.44      0.54        50\n",
      "\n",
      "    accuracy                           0.84       235\n",
      "   macro avg       0.79      0.70      0.72       235\n",
      "weighted avg       0.83      0.84      0.83       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8351\n",
      "Matthews Correlation Coefficient (MCC): 0.4733\n",
      "Balanced Accuracy: 0.6957\n",
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0          176            9\n",
      "Actual 1           28           22\n",
      "Recall (positive=1): 0.4400\n",
      "F2 Score: 0.4762\n",
      "False Negatives: 28\n",
      "GradientBoostingClassifier Confusion Matrix (values only):\n",
      "[[176   9]\n",
      " [ 28  22]]\n",
      "GB default recall: 0.44\n"
     ]
    }
   ],
   "source": [
    "#Gradient_Boosting_Optimization, default GB (no grid or threshold)\n",
    "\n",
    "gb_default = Gradient_Boosting_Optimization(\n",
    "    model=GradientBoostingClassifier(random_state=1945),\n",
    "    parameter_grid=None,\n",
    "    cv_folds=5,\n",
    "    positive_label=1,\n",
    "    optimize_scoring=\"recall\",\n",
    "    auto_calibrate_threshold=False)  #No threshold optimization\n",
    "\n",
    "\n",
    "gb_default.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "gb_default.optimize()\n",
    "gb_default_results = gb_default.evaluate(show_plots=False)\n",
    "print(\"GB default recall:\", gb_default_results[\"classification_report\"][\"1\"][\"recall\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e005e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters Found:\n",
      "{'learning_rate': 0.09, 'max_depth': 4, 'min_samples_leaf': 3, 'n_estimators': 350, 'subsample': 1.0}\n",
      "Best Cross-Validation Score: 0.4480\n",
      "Applied custom decision threshold: 0.591\n",
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       185\n",
      "           1       0.69      0.44      0.54        50\n",
      "\n",
      "    accuracy                           0.84       235\n",
      "   macro avg       0.77      0.69      0.72       235\n",
      "weighted avg       0.82      0.84      0.82       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7955\n",
      "Matthews Correlation Coefficient (MCC): 0.4605\n",
      "Balanced Accuracy: 0.6930\n",
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0          175           10\n",
      "Actual 1           28           22\n",
      "Recall (positive=1): 0.4400\n",
      "F2 Score: 0.4741\n",
      "False Negatives: 28\n",
      "Baseline recall: 0.44\n",
      "Default GB recall: 0.44\n",
      "Grid-search recall: 0.44\n",
      "Grid search best params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.09, 'loss': 'log_loss', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 350, 'n_iter_no_change': None, 'random_state': 1945, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "Grid search decision threshold: 0.5905869627110203\n"
     ]
    }
   ],
   "source": [
    "#Gradient_Boosting_Optimization, grid-search & F2 threshold optimization\n",
    "gb_grid = Gradient_Boosting_Optimization(\n",
    "    model=GradientBoostingClassifier(random_state=1945),\n",
    "    parameter_grid={\n",
    "        \"learning_rate\": [0.09, 0.1, 0.11],\n",
    "        \"n_estimators\": [340, 345, 350,],\n",
    "        \"max_depth\": [4, ],\n",
    "        \"min_samples_leaf\": [1, 3, 5],\n",
    "        \"subsample\": [0.8, 1.0]},\n",
    "    cv_folds=5,\n",
    "    positive_label=1,\n",
    "    optimize_scoring=\"recall\",\n",
    "    auto_calibrate_threshold=True,\n",
    "    threshold_beta=2.0)\n",
    "\n",
    "gb_grid.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "gb_grid.optimize()\n",
    "gb_grid_results = gb_grid.evaluate(show_plots=False)\n",
    "\n",
    "print(\"Baseline recall:\", legacy_results[\"classification_report\"][\"1\"][\"recall\"])\n",
    "print(\"Default GB recall:\", gb_default_results[\"classification_report\"][\"1\"][\"recall\"])\n",
    "print(\"Grid-search recall:\", gb_grid_results[\"recall\"])\n",
    "print(\"Grid search best params:\", gb_grid.best_model.get_params())\n",
    "print(\"Grid search decision threshold:\", gb_grid_results[\"decision_threshold\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8010dd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>false_negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.257310</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  recall  precision  false_negatives\n",
       "0       0.010    0.88   0.257310                6\n",
       "1       0.050    0.82   0.376147                9\n",
       "2       0.100    0.74   0.451220               13\n",
       "3       0.150    0.70   0.507246               15\n",
       "4       0.200    0.64   0.551724               18\n",
       "5       0.250    0.60   0.600000               20\n",
       "6       0.300    0.56   0.608696               22\n",
       "7       0.350    0.48   0.571429               26\n",
       "8       0.400    0.48   0.615385               26\n",
       "9       0.450    0.48   0.631579               26\n",
       "10      0.600    0.44   0.687500               28\n",
       "11      0.737    0.30   0.625000               35\n",
       "12      0.900    0.18   0.692308               41"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Threshold Comparison: \n",
    "thresholds = [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.60, 0.737, 0.90]\n",
    "rows = []\n",
    "\n",
    "for t in thresholds:\n",
    "    gb_grid.set_decision_threshold(t)\n",
    "    res = gb_grid.evaluate(show_plots=False, print_results=False)\n",
    "    rows.append({\n",
    "        \"threshold\": t,\n",
    "        \"recall\": res[\"recall\"],\n",
    "        \"precision\": res[\"classification_report\"][\"1\"][\"precision\"],\n",
    "        \"false_negatives\": res[\"false_negatives\"]})\n",
    "gb_grid.set_decision_threshold(None) \n",
    "threshold_results = pd.DataFrame(rows)\n",
    "threshold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de5c5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Look into threshold differences and also print format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b70e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
