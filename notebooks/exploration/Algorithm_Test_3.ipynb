{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f36854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, random\n",
    "import importlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "#Warning Supression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"skopt\") #Ignore scikit-optimize warning print lines\n",
    "from scipy.linalg import LinAlgWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LinAlgWarning) #For QDA\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) #For LightBoost\n",
    "\n",
    "#Class Import\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\"))) #Allow for imports from src\n",
    "from src.models import ML_Class_2\n",
    "importlib.reload(ML_Class_2) #Ensures file is uptodate!\n",
    "from src.models.ML_Class_2 import Model_Tester_V2\n",
    "\n",
    "#Utils Import\n",
    "from src.models.model_artifacts import (get_artifact_dir, load_model, load_models, save_model, save_models,)\n",
    "ARTIFACT_DIR = get_artifact_dir(\"algorithm_test_3\")\n",
    "from src.models import model_specs\n",
    "importlib.reload(model_specs) #Ensures file is uptodate!\n",
    "from src.models.model_specs import MODEL_SPECS\n",
    "from src.models.perf_utils import track_performance\n",
    "\n",
    "#Set Seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"1945\"\n",
    "random.seed(1945)\n",
    "np.random.seed(1945)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea536005",
   "metadata": {},
   "source": [
    "### Models Tested:\n",
    "\n",
    "| Key | Algorithm | Library |\n",
    "|:----|:-----------|:---------|\n",
    "| **dt** | Decision Tree Classifier | scikit-learn |\n",
    "| **rf** | Random Forest Classifier | scikit-learn |\n",
    "| **et** | Extra Trees Classifier | scikit-learn |\n",
    "| **bag** | Bagging Classifier (Tree Base) | scikit-learn |\n",
    "| **gb** | Gradient Boosting Classifier | scikit-learn |\n",
    "| **ada** | AdaBoost Classifier | scikit-learn |\n",
    "| **qda** | Quadratic Discriminant Analysis | scikit-learn |\n",
    "| **xgb** | XGBoost Classifier | xgboost |\n",
    "| **xgbrf** | XGBoost Random Forest | xgboost |\n",
    "| **lgbm** | LightGBM Classifier | lightgbm |\n",
    "| **cat** | CatBoost Classifier | catboost |\n",
    "\n",
    " **Note:**  \n",
    "Preliminary algorithm tests were done in Algorithm_Test_2. In this notebook, further optimization and comparison are done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c7525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Preprocessing --- \n",
    "\n",
    "#Complied data of convoys\n",
    "#Routes examined are HX, SC, OB, ON, ONS\n",
    "df = pd.read_csv('/Users/matthewplambeck/Desktop/Convoy Predictor/data/processed/Complete_Convoy_Data.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.shape #Test\n",
    "#Drop unecessary/redundent features\n",
    "df = df.drop(columns=['Convoy Number', 'Number of Ships Sunk', 'Depart_Date', 'Arrival/Dispersal Date', 'Number of Escorts Sunk', \\\n",
    "                         'Number of Stragglers Sunk', 'Total Tons of Ships Sunk', 'Escort Sink Percentage', 'Straggler Sink Percentage'])\n",
    "df.reset_index(drop=True).head(3)\n",
    "#Feature Names for later feature analysis:\n",
    "feature_names = list(df)\n",
    "feature_names[:-1] #Drop Risk (y)\n",
    "#Convert Overall Sink Percentage to binary 1( High)\n",
    "df['Risk'] = (df['Overall Sink Percentage'] > 0).astype(int) \n",
    "#Risk is binary based off whether a ship was sunk while in a convoy:  (0 = No Ships Sunk, 1 = At Least One Ship Sunk)\n",
    "X = np.array(df.drop(columns=['Overall Sink Percentage', 'Risk'])) #Remove Overall Sink Percentage as it leaks data\n",
    "y = df['Risk'].values #Prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbec503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Threshold Calibration Helpers ---\n",
    "#Set to True to rerun the full hyperparameter search. When False, the notebook\n",
    "#reloads the last optimized estimator, recalibrates the decision threshold,\n",
    "#and re-evaluates the model so metrics stay in sync with the new beta value.\n",
    "RETRAIN_MODELS = False\n",
    "\n",
    "def prepare_tester(model_key, *, scaler=None, cv_folds=None):\n",
    "    spec = MODEL_SPECS[model_key]\n",
    "    tester = Model_Tester_V2(\n",
    "        model=spec[\"estimator\"],\n",
    "        scaler=scaler,\n",
    "        parameter_grid=spec[\"grid_large\"],\n",
    "        cv_folds=cv_folds or spec.get(\"cv_folds\", 5),\n",
    "        feature_names=feature_names,\n",
    "        model_config=spec[\"config\"],)\n",
    "    tester.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "    if callable(tester.parameter_grid):\n",
    "        tester.parameter_grid = tester.parameter_grid(tester.y_train)\n",
    "    return tester\n",
    "\n",
    "def refresh_model(model_key, tester, *, method=\"halving\", scoring=\"recall\",\n",
    "                  perf_label=None, optimize_kwargs=None):\n",
    "    optimize_kwargs = optimize_kwargs or {}\n",
    "    artifact_path = ARTIFACT_DIR / f\"{model_key}.joblib\"\n",
    "    needs_opt = RETRAIN_MODELS or not artifact_path.exists()\n",
    "\n",
    "    if needs_opt:\n",
    "        def _run_opt():\n",
    "            tester.optimize(scoring=scoring, method=method, **optimize_kwargs)\n",
    "        if perf_label:\n",
    "            track_performance(perf_label)(_run_opt)()\n",
    "        else:\n",
    "            _run_opt()\n",
    "    else:\n",
    "        load_model(model_key, directory=ARTIFACT_DIR, assign_to=tester)\n",
    "\n",
    "    tester._calibrate_threshold()\n",
    "    results = tester.evaluate(show_plots=False)\n",
    "    save_model(model_key, tester, directory=ARTIFACT_DIR)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac3612",
   "metadata": {},
   "source": [
    "**Start of Algorithms Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260ad96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.4493\n",
      "\n",
      "DecisionTreeClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.49      0.64       185\n",
      "           1       0.31      0.84      0.45        50\n",
      "\n",
      "    accuracy                           0.57       235\n",
      "   macro avg       0.61      0.67      0.55       235\n",
      "weighted avg       0.79      0.57      0.60       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7449\n",
      "Matthews Correlation Coefficient (MCC): 0.2751\n",
      "Balanced Accuracy: 0.6659\n",
      "DecisionTreeClassifier Confusion Matrix:\n",
      "[[91 94]\n",
      " [ 8 42]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "dt = prepare_tester(\"dt\")\n",
    "dt_results = refresh_model(\"dt\", dt, method=\"halving\", perf_label=\"dt_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6452869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.3932\n",
      "\n",
      "RandomForestClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       185\n",
      "           1       0.56      0.70      0.62        50\n",
      "\n",
      "    accuracy                           0.82       235\n",
      "   macro avg       0.74      0.78      0.75       235\n",
      "weighted avg       0.84      0.82      0.83       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8128\n",
      "Matthews Correlation Coefficient (MCC): 0.5145\n",
      "Balanced Accuracy: 0.7770\n",
      "RandomForestClassifier Confusion Matrix:\n",
      "[[158  27]\n",
      " [ 15  35]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "rf = prepare_tester(\"rf\")\n",
    "rf_results = refresh_model(\"rf\", rf, method=\"halving\", perf_label=\"rf_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19e1031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.5302\n",
      "\n",
      "ExtraTreesClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89       185\n",
      "           1       0.60      0.64      0.62        50\n",
      "\n",
      "    accuracy                           0.83       235\n",
      "   macro avg       0.75      0.76      0.76       235\n",
      "weighted avg       0.84      0.83      0.84       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8123\n",
      "Matthews Correlation Coefficient (MCC): 0.5156\n",
      "Balanced Accuracy: 0.7632\n",
      "ExtraTreesClassifier Confusion Matrix:\n",
      "[[164  21]\n",
      " [ 18  32]]\n"
     ]
    }
   ],
   "source": [
    "#Extra Trees\n",
    "\n",
    "et = prepare_tester(\"et\")\n",
    "et_results = refresh_model(\"et\", et, method=\"halving\", perf_label=\"et_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87a2ec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.4586\n",
      "\n",
      "BaggingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.84       185\n",
      "           1       0.47      0.70      0.56        50\n",
      "\n",
      "    accuracy                           0.77       235\n",
      "   macro avg       0.69      0.74      0.70       235\n",
      "weighted avg       0.81      0.77      0.78       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8214\n",
      "Matthews Correlation Coefficient (MCC): 0.4310\n",
      "Balanced Accuracy: 0.7446\n",
      "BaggingClassifier Confusion Matrix:\n",
      "[[146  39]\n",
      " [ 15  35]]\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier\n",
    "\n",
    "bag = prepare_tester(\"bag\")\n",
    "bag_results = refresh_model(\"bag\", bag, method=\"halving\", perf_label=\"bag_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ed747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.4570\n",
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       185\n",
      "           1       0.59      0.44      0.51        50\n",
      "\n",
      "    accuracy                           0.82       235\n",
      "   macro avg       0.73      0.68      0.70       235\n",
      "weighted avg       0.80      0.82      0.81       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8036\n",
      "Matthews Correlation Coefficient (MCC): 0.4033\n",
      "Balanced Accuracy: 0.6795\n",
      "GradientBoostingClassifier Confusion Matrix:\n",
      "[[170  15]\n",
      " [ 28  22]]\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "\n",
    "gb = prepare_tester(\"gb\")\n",
    "gb_results = refresh_model(\"gb\", gb, method=\"halving\", perf_label=\"gb_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc4a7712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.1875\n",
      "\n",
      "AdaBoostClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.55      0.69       185\n",
      "           1       0.34      0.86      0.49        50\n",
      "\n",
      "    accuracy                           0.61       235\n",
      "   macro avg       0.64      0.70      0.59       235\n",
      "weighted avg       0.81      0.61      0.65       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7818\n",
      "Matthews Correlation Coefficient (MCC): 0.3334\n",
      "Balanced Accuracy: 0.7030\n",
      "AdaBoostClassifier Confusion Matrix:\n",
      "[[101  84]\n",
      " [  7  43]]\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "\n",
    "ada = prepare_tester(\"ada\")\n",
    "ada_results = refresh_model(\"ada\", ada, method=\"halving\", perf_label=\"ada_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "724355d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.1770\n",
      "\n",
      "QuadraticDiscriminantAnalysis Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.52      0.67       185\n",
      "           1       0.33      0.88      0.48        50\n",
      "\n",
      "    accuracy                           0.60       235\n",
      "   macro avg       0.64      0.70      0.58       235\n",
      "weighted avg       0.81      0.60      0.63       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7897\n",
      "Matthews Correlation Coefficient (MCC): 0.3335\n",
      "Balanced Accuracy: 0.7022\n",
      "QuadraticDiscriminantAnalysis Confusion Matrix:\n",
      "[[97 88]\n",
      " [ 6 44]]\n"
     ]
    }
   ],
   "source": [
    "#QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = prepare_tester(\"qda\", scaler=StandardScaler())\n",
    "qda_results = refresh_model(\"qda\", qda, method=\"halving\", perf_label=\"qda_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cabe03e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.6045\n",
      "\n",
      "XGBClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       185\n",
      "           1       0.53      0.46      0.49        50\n",
      "\n",
      "    accuracy                           0.80       235\n",
      "   macro avg       0.70      0.68      0.68       235\n",
      "weighted avg       0.79      0.80      0.79       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7670\n",
      "Matthews Correlation Coefficient (MCC): 0.3725\n",
      "Balanced Accuracy: 0.6759\n",
      "XGBClassifier Confusion Matrix:\n",
      "[[165  20]\n",
      " [ 27  23]]\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "\n",
    "xgb = prepare_tester(\"xgb\")\n",
    "xgb_results = refresh_model(\"xgb\", xgb, method=\"halving\", perf_label=\"xgb_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7f38f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.5835\n",
      "\n",
      "XGBRFClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       185\n",
      "           1       0.39      0.74      0.51        50\n",
      "\n",
      "    accuracy                           0.69       235\n",
      "   macro avg       0.65      0.71      0.64       235\n",
      "weighted avg       0.80      0.69      0.72       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7942\n",
      "Matthews Correlation Coefficient (MCC): 0.3506\n",
      "Balanced Accuracy: 0.7105\n",
      "XGBRFClassifier Confusion Matrix:\n",
      "[[126  59]\n",
      " [ 13  37]]\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Random Forest\n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "xgbrf = prepare_tester(\"xgbrf\")\n",
    "xgbrf_results = refresh_model(\"xgbrf\", xgbrf, method=\"halving\", perf_label=\"xgbrf_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36d69661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.1794\n",
      "\n",
      "LGBMClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       185\n",
      "           1       0.46      0.52      0.49        50\n",
      "\n",
      "    accuracy                           0.77       235\n",
      "   macro avg       0.67      0.68      0.67       235\n",
      "weighted avg       0.78      0.77      0.77       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7469\n",
      "Matthews Correlation Coefficient (MCC): 0.3437\n",
      "Balanced Accuracy: 0.6789\n",
      "LGBMClassifier Confusion Matrix:\n",
      "[[155  30]\n",
      " [ 24  26]]\n"
     ]
    }
   ],
   "source": [
    "#LightGBM\n",
    "\n",
    "lgbm = prepare_tester(\"lgbm\", cv_folds=3)\n",
    "lgbm_results = refresh_model(\"lgbm\", lgbm, method=\"random\", perf_label=\"lgbm_optimize\", optimize_kwargs={\"n_iter\": 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faf8ce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.0381\n",
      "\n",
      "CatBoostClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82       185\n",
      "           1       0.43      0.66      0.52        50\n",
      "\n",
      "    accuracy                           0.74       235\n",
      "   macro avg       0.66      0.71      0.67       235\n",
      "weighted avg       0.79      0.74      0.76       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7717\n",
      "Matthews Correlation Coefficient (MCC): 0.3681\n",
      "Balanced Accuracy: 0.7111\n",
      "CatBoostClassifier Confusion Matrix:\n",
      "[[141  44]\n",
      " [ 17  33]]\n"
     ]
    }
   ],
   "source": [
    "#CatBoost\n",
    "\n",
    "cat = prepare_tester(\"cat\")\n",
    "cat_results = refresh_model(\"cat\", cat, method=\"halving\", perf_label=\"cat_optimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test Of Loading Trained Models ---\n",
    "\n",
    "dt_reload = prepare_tester(\"dt\")\n",
    "load_model(\"dt\", directory=ARTIFACT_DIR, assign_to=dt_reload)\n",
    "dt_reload_results = dt_reload.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33315572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Method Used for Optimization and Orginal Tests --- \n",
    "\n",
    "# #Decision Tree\n",
    "\n",
    "# spec = MODEL_SPECS[\"dt\"]\n",
    "# dt = Model_Tester_V2(\n",
    "#     model=spec[\"estimator\"],\n",
    "#     parameter_grid=spec[\"grid_large\"],\n",
    "#     cv_folds=5,\n",
    "#     feature_names=feature_names,\n",
    "#     model_config=spec[\"config\"],)\n",
    "    \n",
    "# dt.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "# @track_performance(\"dt_optimize\")\n",
    "# def run_dt_opt():\n",
    "#     dt.optimize(scoring=\"recall\", method='halving')\n",
    "\n",
    "# run_dt_opt()\n",
    "# dt_results = dt.evaluate(show_plots=False)\n",
    "\n",
    "# save_model(\"dt\", dt, directory=ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72128604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Method: Grid\n",
      "Best Hyperparameters Found:\n",
      "{'learning_rate': 0.12, 'max_depth': 3, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300, 'subsample': 0.7}\n",
      "Best Cross-Validation Recall: 0.4677\n",
      "Performance Stats:\n",
      "gb2_optimize completed in 63.33mins | Î”RSS -168.00 MB | CPU 90.5%\n",
      "Applied decision threshold: 0.3930\n",
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       185\n",
      "           1       0.62      0.58      0.60        50\n",
      "\n",
      "    accuracy                           0.83       235\n",
      "   macro avg       0.75      0.74      0.75       235\n",
      "weighted avg       0.83      0.83      0.83       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8248\n",
      "Matthews Correlation Coefficient (MCC): 0.4939\n",
      "Balanced Accuracy: 0.7414\n",
      "GradientBoostingClassifier Confusion Matrix:\n",
      "[[167  18]\n",
      " [ 21  29]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/matthewplambeck/Desktop/Convoy Predictor/artifacts/algorithm_test_3/gb2.joblib')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Comparison To GB Model in Classification_Test_2.ipynb --- \n",
    "\n",
    "spec = MODEL_SPECS[\"gb\"]\n",
    "gb2 = Model_Tester_V2(\n",
    "    model=spec[\"estimator\"],\n",
    "    parameter_grid=spec[\"grid_large\"],\n",
    "    cv_folds=5,\n",
    "    feature_names=feature_names,\n",
    "    model_config=spec[\"config\"],)\n",
    "\n",
    "gb2.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "@track_performance(\"gb2_optimize\")\n",
    "def run_gb_opt():\n",
    "    gb2.optimize(scoring=\"recall\", method='grid')\n",
    "\n",
    "run_gb_opt()\n",
    "gb2_results = gb2.evaluate(show_plots=False)\n",
    "\n",
    "save_model(\"gb2\", gb2, directory=ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c33d36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
