{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18b6044",
   "metadata": {},
   "source": [
    "## Notebook to test an ensemble learning model of the top 3-5 model from Algorithm_Test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353f05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, random\n",
    "import importlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "#Warning Supression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"skopt\") #Ignore scikit-optimize warning print lines\n",
    "from scipy.linalg import LinAlgWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LinAlgWarning) #For QDA\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) #For LightBoost\n",
    "\n",
    "#Class Import\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\"))) #Allow for imports from src\n",
    "from src.models import ML_Class_2\n",
    "importlib.reload(ML_Class_2) #Ensures file is uptodate!\n",
    "from src.models.ML_Class_2 import Model_Tester_V2\n",
    "\n",
    "#Utils Import\n",
    "from src.models.model_artifacts import (get_artifact_dir, load_model, load_models, save_model, save_models,)\n",
    "ARTIFACT_DIR = get_artifact_dir(\"algorithm_test_3\")\n",
    "from src.models import model_specs\n",
    "importlib.reload(model_specs) #Ensures file is uptodate!\n",
    "from src.models.model_specs import MODEL_SPECS\n",
    "from src.models.perf_utils import track_performance\n",
    "\n",
    "#Set Seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"1945\"\n",
    "random.seed(1945)\n",
    "np.random.seed(1945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6dc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Preprocessing --- \n",
    "\n",
    "#Complied data of convoys\n",
    "#Routes examined are HX, SC, OB, ON, ONS\n",
    "df = pd.read_csv('/Users/matthewplambeck/Desktop/Convoy Predictor/data/processed/Complete_Convoy_Data.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.shape #Test\n",
    "#Drop unecessary/redundent features\n",
    "df = df.drop(columns=['Convoy Number', 'Number of Ships Sunk', 'Depart_Date', 'Arrival/Dispersal Date', 'Number of Escorts Sunk', \\\n",
    "                         'Number of Stragglers Sunk', 'Total Tons of Ships Sunk', 'Escort Sink Percentage', 'Straggler Sink Percentage'])\n",
    "df.reset_index(drop=True).head(3)\n",
    "#Feature Names for later feature analysis:\n",
    "feature_names = list(df)\n",
    "feature_names[:-1] #Drop Risk (y)\n",
    "#Convert Overall Sink Percentage to binary 1( High)\n",
    "df['Risk'] = (df['Overall Sink Percentage'] > 0).astype(int) \n",
    "#Risk is binary based off whether a ship was sunk while in a convoy:  (0 = No Ships Sunk, 1 = At Least One Ship Sunk)\n",
    "X = np.array(df.drop(columns=['Overall Sink Percentage', 'Risk'])) #Remove Overall Sink Percentage as it leaks data\n",
    "y = df['Risk'].values #Prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.5968\n",
      "\n",
      "ExtraTreesClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       185\n",
      "           1       0.69      0.62      0.65        50\n",
      "\n",
      "    accuracy                           0.86       235\n",
      "   macro avg       0.79      0.77      0.78       235\n",
      "weighted avg       0.86      0.86      0.86       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8123\n",
      "Matthews Correlation Coefficient (MCC): 0.5662\n",
      "Balanced Accuracy: 0.7722\n",
      "ExtraTreesClassifier Confusion Matrix:\n",
      "[[171  14]\n",
      " [ 19  31]]\n"
     ]
    }
   ],
   "source": [
    "# --- Extra Trees ---\n",
    "\n",
    "spec = MODEL_SPECS[\"et\"]\n",
    "et = Model_Tester_V2(\n",
    "    model=spec[\"estimator\"],\n",
    "    parameter_grid=spec[\"grid_large\"],\n",
    "    cv_folds=5,\n",
    "    feature_names=feature_names,\n",
    "    model_config=spec[\"config\"],)\n",
    "et.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "#Load trained model\n",
    "load_model(\"et\", directory=ARTIFACT_DIR, assign_to=et)\n",
    "et_results = et.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f6bcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.5057\n",
      "\n",
      "RandomForestClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       185\n",
      "           1       0.64      0.60      0.62        50\n",
      "\n",
      "    accuracy                           0.84       235\n",
      "   macro avg       0.77      0.75      0.76       235\n",
      "weighted avg       0.84      0.84      0.84       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.8128\n",
      "Matthews Correlation Coefficient (MCC): 0.5199\n",
      "Balanced Accuracy: 0.7541\n",
      "RandomForestClassifier Confusion Matrix:\n",
      "[[168  17]\n",
      " [ 20  30]]\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest ---\n",
    "\n",
    "spec = MODEL_SPECS[\"rf\"]\n",
    "rf = Model_Tester_V2(\n",
    "    model=spec[\"estimator\"],\n",
    "    parameter_grid=spec[\"grid_large\"],\n",
    "    cv_folds=5,\n",
    "    feature_names=feature_names,\n",
    "    model_config=spec[\"config\"],)\n",
    "rf.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "#Load trained model\n",
    "load_model(\"rf\", directory=ARTIFACT_DIR, assign_to=rf)\n",
    "rf_results = rf.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d4de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.9907\n",
      "\n",
      "GradientBoostingClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       185\n",
      "           1       0.71      0.20      0.31        50\n",
      "\n",
      "    accuracy                           0.81       235\n",
      "   macro avg       0.77      0.59      0.60       235\n",
      "weighted avg       0.80      0.81      0.77       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7845\n",
      "Matthews Correlation Coefficient (MCC): 0.3084\n",
      "Balanced Accuracy: 0.5892\n",
      "GradientBoostingClassifier Confusion Matrix:\n",
      "[[181   4]\n",
      " [ 40  10]]\n"
     ]
    }
   ],
   "source": [
    "# --- GradientBoosting ---\n",
    "\n",
    "spec = MODEL_SPECS[\"gb\"]\n",
    "gb = Model_Tester_V2(\n",
    "    model=spec[\"estimator\"],\n",
    "    parameter_grid=spec[\"grid_large\"],\n",
    "    cv_folds=5,\n",
    "    feature_names=feature_names,\n",
    "    model_config=spec[\"config\"],)\n",
    "gb.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "#Load trained model\n",
    "load_model(\"gb\", directory=ARTIFACT_DIR, assign_to=gb)\n",
    "gb_results = gb.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a60ad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.6515\n",
      "\n",
      "AdaBoostClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       185\n",
      "           1       0.54      0.62      0.58        50\n",
      "\n",
      "    accuracy                           0.81       235\n",
      "   macro avg       0.72      0.74      0.73       235\n",
      "weighted avg       0.82      0.81      0.81       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7818\n",
      "Matthews Correlation Coefficient (MCC): 0.4578\n",
      "Balanced Accuracy: 0.7397\n",
      "AdaBoostClassifier Confusion Matrix:\n",
      "[[159  26]\n",
      " [ 19  31]]\n"
     ]
    }
   ],
   "source": [
    "# --- AdaBoostClassifier ---\n",
    "\n",
    "#Notes: Compare With GB once new param grid is fit\n",
    "\n",
    "spec = MODEL_SPECS[\"ada\"]\n",
    "ada = Model_Tester_V2(\n",
    "    model=spec[\"estimator\"],\n",
    "    parameter_grid=spec[\"grid_large\"],\n",
    "    cv_folds=5,\n",
    "    feature_names=feature_names,\n",
    "    model_config=spec[\"config\"],)\n",
    "ada.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "#Load trained model\n",
    "load_model(\"ada\", directory=ARTIFACT_DIR, assign_to=ada)\n",
    "ada_results = ada.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8970c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.4781\n",
      "\n",
      "QuadraticDiscriminantAnalysis Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85       185\n",
      "           1       0.48      0.70      0.57        50\n",
      "\n",
      "    accuracy                           0.77       235\n",
      "   macro avg       0.69      0.75      0.71       235\n",
      "weighted avg       0.82      0.77      0.79       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7897\n",
      "Matthews Correlation Coefficient (MCC): 0.4374\n",
      "Balanced Accuracy: 0.7473\n",
      "QuadraticDiscriminantAnalysis Confusion Matrix:\n",
      "[[147  38]\n",
      " [ 15  35]]\n"
     ]
    }
   ],
   "source": [
    "# --- QuadraticDiscriminantAnalysis ---\n",
    "\n",
    "spec = MODEL_SPECS[\"qda\"]\n",
    "qda = Model_Tester_V2(\n",
    "    model=spec[\"estimator\"],\n",
    "    parameter_grid=spec[\"grid_large\"],\n",
    "    cv_folds=5,\n",
    "    feature_names=feature_names,\n",
    "    model_config=spec[\"config\"],)\n",
    "qda.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "#Load trained model\n",
    "load_model(\"qda\", directory=ARTIFACT_DIR, assign_to=qda)\n",
    "qda_results = qda.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33151c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied decision threshold: 0.6253\n",
      "\n",
      "XGBRFClassifier Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       185\n",
      "           1       0.53      0.64      0.58        50\n",
      "\n",
      "    accuracy                           0.80       235\n",
      "   macro avg       0.72      0.74      0.73       235\n",
      "weighted avg       0.82      0.80      0.81       235\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7942\n",
      "Matthews Correlation Coefficient (MCC): 0.4586\n",
      "Balanced Accuracy: 0.7443\n",
      "XGBRFClassifier Confusion Matrix:\n",
      "[[157  28]\n",
      " [ 18  32]]\n"
     ]
    }
   ],
   "source": [
    "# --- XGBRFClassifier ---\n",
    "\n",
    "spec = MODEL_SPECS[\"xgbrf\"]\n",
    "xgbrf = Model_Tester_V2(\n",
    "    model=spec[\"estimator\"],\n",
    "    parameter_grid=spec[\"grid_large\"],\n",
    "    cv_folds=5,\n",
    "    feature_names=feature_names,\n",
    "    model_config=spec[\"config\"],)\n",
    "xgbrf.train_test_split(X, y, train_size=0.8, random_state=1945)\n",
    "\n",
    "#Load trained model\n",
    "load_model(\"xgbrf\", directory=ARTIFACT_DIR, assign_to=xgbrf)\n",
    "xgbrf_results = xgbrf.evaluate(show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create Ensemble Model with top 3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c47185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1728cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173374ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b42c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3482d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec832a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c4166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c74fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9998fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "161401a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
