{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653f534c",
   "metadata": {},
   "source": [
    "**The Final Analysis Notebook For The Convoy Data Ensemble Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c874bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import sys, os, random\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (roc_auc_score, recall_score, precision_score, f1_score, matthews_corrcoef, \\\n",
    "                             balanced_accuracy_score, confusion_matrix,classification_report )\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "#Warning Supression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"skopt\") #Ignore scikit-optimize warning print lines\n",
    "from scipy.linalg import LinAlgWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LinAlgWarning) #For QDA\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) #For LightBoost\n",
    "\n",
    "#Class Import\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\"))) #Allow for imports from src\n",
    "from src.models import ML_Class_2\n",
    "importlib.reload(ML_Class_2) #Ensures file is uptodate!\n",
    "from src.models.ML_Class_2 import Model_Tester_V2\n",
    "\n",
    "#Utils Import\n",
    "from src.models.model_artifacts import (get_artifact_dir, load_model, load_models, save_model, save_models,)\n",
    "ARTIFACT_DIR = get_artifact_dir(\"algorithm_test_3\")\n",
    "from src.models import model_specs\n",
    "importlib.reload(model_specs) #Ensures file is uptodate!\n",
    "from src.models.model_specs import MODEL_SPECS\n",
    "from src.models.perf_utils import track_performance\n",
    "\n",
    "#Set Seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"1945\"\n",
    "random.seed(1945)\n",
    "np.random.seed(1945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f823e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complied data of convoys\n",
    "#Routes examined are HX, SC, OB, ON, ONS\n",
    "df = pd.read_csv('/Users/matthewplambeck/Desktop/Convoy Predictor/data/processed/Complete_Convoy_Data.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "# df.shape #Test\n",
    "#Drop unecessary/redundent features\n",
    "df = df.drop(columns=['Convoy Number', 'Number of Ships Sunk', 'Depart_Date', 'Arrival/Dispersal Date', 'Number of Escorts Sunk', \\\n",
    "                         'Number of Stragglers Sunk', 'Total Tons of Ships Sunk', 'Escort Sink Percentage', 'Straggler Sink Percentage'])\n",
    "df.reset_index(drop=True).head(3)\n",
    "#Convert Overall Sink Percentage to binary 1( High)\n",
    "df['Risk'] = (df['Overall Sink Percentage'] > 0).astype(int) \n",
    "#Risk is binary based off whether a ship was sunk while in a convoy:  (0 = No Ships Sunk, 1 = At Least One Ship Sunk)\n",
    "X = np.array(df.drop(columns=['Overall Sink Percentage', 'Risk'])) #Remove Overall Sink Percentage as it leaks data\n",
    "y = df['Risk'].values #Prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc4e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Names for later feature analysis:\n",
    "X_df = df.drop(columns=['Overall Sink Percentage', 'Risk'])\n",
    "X = X_df.values\n",
    "y = df['Risk'].values\n",
    "feature_names = list(X_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00920d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23149d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcd1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9172ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06924884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690737d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
